<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qin Yuan&#39;s blog</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="qyuan.top/"/>
  <updated>2019-11-26T12:23:30.186Z</updated>
  <id>qyuan.top/</id>
  
  <author>
    <name>Qin Yuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>以太坊Ghost协议</title>
    <link href="qyuan.top/2019/11/26/ghost/"/>
    <id>qyuan.top/2019/11/26/ghost/</id>
    <published>2019-11-26T12:16:44.000Z</published>
    <updated>2019-11-26T12:23:30.186Z</updated>
    
    <content type="html"><![CDATA[<p>在比特币中，每个区块的出块时间被设置为10分钟，为什么需要10分钟呢？按照常识来说，出块速度越快可以打包的交易就越多，系统的吞吐率也就越高。</p>
<a id="more"></a>
<p>根据前文可知，想要提高出块速度就要降低挖矿难度，我们假设这样一种场景；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/ghost/1.png?raw=true" width="70%" height="70%"></p>
<p>当挖矿难度降低以后，最新区块有可能被多个矿工同时挖出，比如上图中的A,B,C,D,E区块可能被网络中的不同矿工同时挖出，当A被挖出的时候，还没广播到其余矿工，其余矿工还在基于区块4继续挖矿，这样就会产生区块B,C,D,E。</p>
<p>由于其余矿工接收到最长高区块后，就不会再接收同一高度的区块了，相当这个区块相当于将网络进行了分区，分为了5个区域A,B,C,D,E，每个矿工按照自己接收到的最长链进行挖矿，这样算力就被分散了。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/ghost/2.png?raw=true" width="70%" height="70%"></p>
<p>这个时候不需要51%的算力，只需要21%的算力就可以快速挖出最长链，提高出块速度后链更容易产生分叉，一定程度上浪费了算力，也降低了链的安全性。</p>
<p>甚至在更坏的情况下，频繁出现分叉，在分叉上继续出现分叉导致整个链不可用。</p>
<h3 id="以太坊"><a href="#以太坊" class="headerlink" title="以太坊"></a>以太坊</h3><p>以太坊中的出块时间被缩短为了15s，意味着比特币中长出块时间所解决的问题都将在以太坊中暴露出来。<br>在图二中，假如区块A由矿池挖出，后续矿池的挖矿算力都会基于区块A继续挖掘，而其他节点可能基于B，C挖掘但是由于矿池网络更好，连接了更多的节点，新区块的广播更快的传播到网络中其它节点，因为这些优势，矿池的区块更可能成为最长链，而其余的的分叉区块将得不到挖矿奖励，显然不利于个人矿工或者小矿池。</p>
<p>假设一个大型矿池A打包了区块A，继续在A的基础上挖A1，而挖出区块B的矿工为了自己的挖出的区块不被丢弃，保护自己的利益就需要继续挖B1希望能成最长链，这显然不是以太坊所希望的。</p>
<p>聚焦一下问题；</p>
<ul>
<li>出块速度快导致链频繁分叉，难以确定最长链；</li>
<li>矿池因为网络，算力优势具备了不对称的优势；</li>
</ul>
<p>为了解决这两个问题，以太坊引入了Ghost协议来解决这些问题。<br>以太坊中出现了频繁分叉，为了尽快确定最长链就需要尽快的合并这些分叉。</p>
<h3 id="叔块（Uncle-block）"><a href="#叔块（Uncle-block）" class="headerlink" title="叔块（Uncle block）"></a>叔块（Uncle block）</h3><p>以太坊创造了一个新的名词叔块，如下图所示；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/ghost/3.png?raw=true" width="70%" height="70%"></p>
<p>对高度4的区块来说，3号区块是他的父区块，两个叔块是3号区块的兄弟区块，是4号区块的叔叔，于是，叔块就是这么得名的。</p>
<blockquote>
<p>虚线部分仅仅用来陈述关系，不表示有实际连接</p>
</blockquote>
<p>在Ghost协议中，当区块4被挖出的时候可以包含一个叔块，叔块获得7/8的出块奖励，而区块4可以得到1/32的额外奖励。</p>
<blockquote>
<p>一个区块最多包含两个叔父区块。</p>
</blockquote>
<p>但是这样做有几个问题；</p>
<ul>
<li>叔父区块可能不只两个，这样一次就可能不能包含全部区块；</li>
<li>可能区块4被挖出的时候，还没有感知到叔父区块，这样到只能到挖出区块5的时候才能在包含区块4的叔父区块；</li>
<li>可能区块4由于某些原因就是不包含叔父区块，比如和挖出叔父区块的节点有竞争关系；</li>
</ul>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/ghost/4.png?raw=true" width="70%" height="70%"></p>
<p>如果一个区块允许包含过多的叔块，就会导致以太坊的产出过多，币价贬值，但是又为了保护矿工利益和尽快合并临时分叉，ghost协议放宽了叔父区块的限制，比如区块5也是可以包含区块4的叔父区块。</p>
<p>为了避免无限制的包含叔父区块，以太坊又加了这样一条限制，每一个区块只能包含自己前7个区块的叔块奖励，而且每离自己远一个区块，那个叔父区块获得的奖励就减小1/8。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/ghost/5.png?raw=true" width="70%" height="70%"></p>
<blockquote>
<p>叔块获得最少区块的奖励是2/8</p>
</blockquote>
<p>通过这样的方式就解决了上面的前两个问题，第三个问题也很好解决，因为一个矿工很难连续挖出区块，所以也可以解决。</p>
<blockquote>
<p>往前推7个区块是为了避免实现的复杂性，因为既要保存区块，又要记录同一高度区块的大量区块会导致状态非常复杂。</p>
</blockquote>
<p>还要注意的一点是包含的叔父区中的交易并不执行，叔父区块的交易不一定是非法的，但是如果执行则可能造成主链上交易变成非法交易，所以并不需要执行。</p>
<p>包含的叔块只能是单个区块，如果在叔块后还有区块则不包含，这个也很好理解，如果是分叉的第一个区块可以理解为是巧合或者网络传播太慢，但是当感知到这个不是最长链的时候，还基于分叉挖矿则可以认为是恶意节点。</p>
]]></content>
    
    <summary type="html">
    
      以太坊Ghost协议
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>深入理解比特币脚本</title>
    <link href="qyuan.top/2019/11/20/bitcoinScript/"/>
    <id>qyuan.top/2019/11/20/bitcoinScript/</id>
    <published>2019-11-20T10:53:29.000Z</published>
    <updated>2019-11-26T12:02:16.745Z</updated>
    
    <content type="html"><![CDATA[<p>每一笔交易除了铸币交易（coinbase）外，每一笔交易都拥有至少一个输入（TxIn）和至少一个输出（TxOut），和我们直觉上理解的交易的TxIn和TxOut应该是数字不太一样，在比特币中是以脚本的形式存在。</p>
<a id="more"></a>
<h3 id="比特币脚本"><a href="#比特币脚本" class="headerlink" title="比特币脚本"></a>比特币脚本</h3><p>比特币脚本是一种基于栈的脚本语言，不是图灵完备的，在比特币没有账户的概念，谁拥有这笔交易的输出谁就可以花费这笔交易中的比特币，为了证明拥有这笔交易的输出就需要提供密钥接受验证，验证通过就可以花费这笔交易的输出。</p>
<blockquote>
<p>其基本的设计思路是，谁能提供一个签名和一个公钥，让这个脚本运行通过，谁就能花费交易中包含的BTC。</p>
</blockquote>
<p>执行的脚本由输入和输出拼接而成，如下图所示；<br><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/bitcoinScript/1.jpg?raw=true" width="110%" height="50%"></p>
<p>比特币提供了三种输入输入脚本的形式，分别是<code>Pay to Publish Key</code>，<code>Pay to Publish Key Hash</code>和<code>Pay to Script Hash</code>。</p>
<h5 id="公钥支付（Pay-to-Publish-Key）"><a href="#公钥支付（Pay-to-Publish-Key）" class="headerlink" title="公钥支付（Pay to Publish Key）"></a>公钥支付（Pay to Publish Key）</h5><p>输出脚本直接给出了收款人的公钥，输入脚本提供了用私钥对整个交易的签名，最后通过<code>OP_CHECKSIG</code>验证。<br>我们知道签名算法是私钥签名公钥验证，如果通过验证，则证明这个行为确实是私钥拥有者所为，在这个例子中，花费交易用私钥对这笔交易进行签名，而上一笔输出交易用公钥对这笔花费交易的私钥进行验证，验证通过后，就可以证明这个交易确实是私钥拥有者做出的，并非冒牌。</p>
<p>在比特币脚本中是这样表示的；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">input script:</div><div class="line">    OP_PUSHDATA(Sig)</div><div class="line">output script:</div><div class="line">    OP_PUSHDATA(PubKey)</div><div class="line">    OP_CHECKSIG</div></pre></td></tr></table></figure></p>
<p>首先 <code>OP_PUSHDATA(Sig)</code>和<code>OP_PUSHDATA(PubKey)</code>将Sig和PubKey压入栈中</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/bitcoinScript/2.png?raw=true" width="20%" height="50%"></p>
<p>接着 <code>OP_CHECKSIG</code> 弹出栈顶两个元素验证签名</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/bitcoinScript/3.png?raw=true" width="20%" height="50%"></p>
<p>栈中结果是True，证明私钥拥有者同时也拥有花费这笔交易Out的权利。</p>
<h5 id="公钥哈希支付（Pay-to-Public-Key-Hash）"><a href="#公钥哈希支付（Pay-to-Public-Key-Hash）" class="headerlink" title="公钥哈希支付（Pay to Public Key Hash）"></a>公钥哈希支付（Pay to Public Key Hash）</h5><p>在<code>Pay to Publish Key</code>中，输出脚本中直接暴露了下一笔交易花费者的公钥，显然是不太合理的，于是又有了第二种输出脚本的类型<code>Pay to Public Key Hash</code>。<br><code>Pay to Public Key Hash</code>类型的输出脚本直接给出了收款人公钥的哈希，输入脚本提供了用私钥对整个交易的签名，同时也提供了自己的公钥用作验证，整个过程大同小异。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">input script:</div><div class="line">    OP_PUSHDATA(Sig)  //压入签名</div><div class="line">    OP_PUSHDATA(PublicKey)  //压入公钥</div><div class="line">output script:</div><div class="line">    OP_DUP  //复制栈顶元素，再压入栈</div><div class="line">    OP_HASH160  //弹出栈顶元素，取哈希在压入栈</div><div class="line">    OP_PUSHDATA(PubKeyHash)  //压入输出脚本提供的公钥哈希</div><div class="line">    OP_EQUALVERIFY   //弹出栈顶元素，比较是否相等</div><div class="line">    OP_CHECKSIG   //公钥检查签名是否正确</div></pre></td></tr></table></figure></p>
<h5 id="脚本哈希支付（Pay-to-Script-Hash）"><a href="#脚本哈希支付（Pay-to-Script-Hash）" class="headerlink" title="脚本哈希支付（Pay to Script Hash）"></a>脚本哈希支付（Pay to Script Hash）</h5><p>这种形式的输出脚本是收款人提供脚本（redeemScript）的哈希，到时候收款人要花费这笔交易的时候需要输入脚本的内容和签名，验证的时候分两步；</p>
<ul>
<li>验证输入脚本的哈希是否与输出脚本中的哈希值匹配</li>
<li>反序列化并执行redeemScript，验证input script给出的签名是否正确</li>
</ul>
<blockquote>
<p>采用BIP16的方案<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">input script:</div><div class="line">    ...</div><div class="line">    OP_PUSHDATA(Sig)          </div><div class="line">    ...</div><div class="line">    OP_PUSHDATA(serialized redeemScript)  </div><div class="line">output script:</div><div class="line">    OP_HASH160                   </div><div class="line">    OP_PUSHDATA(redeemScriptHash)  </div><div class="line">    OP_EQUAL</div></pre></td></tr></table></figure></p>
</blockquote>
<p>其实可以用<code>Pay to Script Hash</code>实现<code>Pay to Public Key</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">redeemScript:</div><div class="line">    PUSHDATA(PubKey)</div><div class="line">    CHECKSIG   </div><div class="line">input script</div><div class="line">    PUSHDATA(Sig)</div><div class="line">    PUSHDATA(serialized redeemScript)</div><div class="line">output script:</div><div class="line">    HASH160</div><div class="line">    PUSDHDATA(redeemScriptHash)</div><div class="line">    EQUAL</div></pre></td></tr></table></figure></p>
<p><code>Pay to Script Hash</code>在比特币最初版本是没有的，后期软分叉加入，最重要的一点是对多重签名的支持。</p>
<blockquote>
<p>多重签名中，只要提超过供指定数量即可，容忍了一定程度的私钥丢失</p>
</blockquote>
<p>原来的多重签名需要外部用户提供一一对应的公钥，一共有多少公钥，几个公钥通过验证就可以完成交易，对用户比较繁琐，现在使用<code>Pay to Script Hash</code>将整个过程打包到脚本中，对外部用户来说降低了多重签名的复杂性，将复杂性转移到了系统中。</p>
<h5 id="Proof-of-Burn"><a href="#Proof-of-Burn" class="headerlink" title="Proof of Burn"></a>Proof of Burn</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">output script</div><div class="line">    RETURN</div><div class="line">    ...</div></pre></td></tr></table></figure>
<p>包含了这样的output script的output被称为Provably Unspendable/Prunable Outputs。<br>假如有一个交易的input指向这个output，不论input里的input script如何设计，执行到RETURN这个命令之后都会直接返回false，RETURN后面的其他指令也就不会执行了，所以这个output无法再被花出去，对应的UTXO也就可以被剪枝了，无需全节点继续保存。</p>
<p>应用场景；</p>
<ul>
<li>永久存储一些信息，比如在某个时间证明存在某些事情，比如在2019年1月1日把知识产权的哈希放到链上，当以后产生纠纷的时候，你把知识产权公布出来，知识产权的哈希在特定时间已经上链，就可以证明你在特定时间已经知道了这个知识产权。</li>
<li>代币转换，比如你把一些比特币转换成其他数字货币，你需要通过这种方式来证明你付出了一些代价。</li>
<li>销毁比特币。</li>
</ul>
<p>其中在比特币脚本中已经出现了智能合约的雏形。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;每一笔交易除了铸币交易（coinbase）外，每一笔交易都拥有至少一个输入（TxIn）和至少一个输出（TxOut），和我们直觉上理解的交易的TxIn和TxOut应该是数字不太一样，在比特币中是以脚本的形式存在。&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="比特币" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="比特币" scheme="qyuan.top/tags/%E6%AF%94%E7%89%B9%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>比特币挖矿原理</title>
    <link href="qyuan.top/2019/11/11/mining-algo/"/>
    <id>qyuan.top/2019/11/11/mining-algo/</id>
    <published>2019-11-11T13:01:52.000Z</published>
    <updated>2019-11-18T12:02:52.640Z</updated>
    
    <content type="html"><![CDATA[<p>比特币网络中，源源不断的收到交易，需要节点不断的打包这些交易，而网络中的所有节点都是对等的，如何判断谁可以打包这些交易，如何避免重复打包这些交易呢？</p>
<a id="more"></a>
<p>这个时候就需要用到<code>工作量证明（PoW，Proof-of-Work）</code>的方式决定记账权。</p>
<p>网络中的任何全节点，都可以试图创建区块，但区块只有在至少满足下列条件时创建的区块才会被其他节点认可和接受。</p>
<ul>
<li>区块中包含的交易都是合法的；</li>
<li>区块哈希要小于等于一个目标值；</li>
</ul>
<p>要满足第一个条件很简单，节点只要将每笔交易都验证一遍，丢弃掉不合法的交易即可。但要满足第二个条件就需要挖矿。</p>
<h3 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a>挖矿</h3><p>比特币挖矿就是找到一个随机数（Nonce）参与哈希运算Hash（Block Header），使得最后得到的哈希值符合难度要求，用公式表示就是<code>Hash（Block Header）&lt;= target</code></p>
<blockquote>
<p>比特币采用的哈希算法是 SHA-256 ，也就是说最后会产生256位的输出，一共2^256种可能的取值。</p>
</blockquote>
<p>最后得到的哈希值小于target的意思是把哈希后得到的bytes转换成数字后小于target转换成的数字。</p>
<p>举个例子，直观的感受一下挖矿的难度;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">SHA-256计算123的值</div><div class="line">a665a45920422f9d417e4867efdc4fb8a04a1f3fff1fa07e998e86f7f7a27ae3</div><div class="line"></div><div class="line">下面这段字符是比特币第1000个区块的哈希（2009年1月产生）；        </div><div class="line">00000000c937983704a73af28acdec37b049d214adbda81d7e2a3dd146f6ed09</div><div class="line">可以看到前面有8个0，虽然哈希值的生成是随机的，但是生成前面有8个0的值对计算机穷举来说也并不算太难。</div><div class="line"></div><div class="line">再看一下这段字符，是比特币第560000个区块的哈希(2019年1月产生)；</div><div class="line">0000000000000000002c7b276daf6efb2b6aa68e2ce3be67ef925b3264ae7122</div><div class="line">可以看到前面有18个0，要生成满足这个条件的哈希对于普通电脑来说几乎是不可能完成的任务了。</div></pre></td></tr></table></figure></p>
<p>简单来看挖矿难度的高低就是生成区块头的哈希值有多少0。</p>
<h3 id="挖矿难度"><a href="#挖矿难度" class="headerlink" title="挖矿难度"></a>挖矿难度</h3><p>在比特币系统中出块时间被设置为一个常数10分钟，但是挖出区块的速度并不是固定的，而是随着挖矿难度的变化在10分钟上下浮动， 挖矿难度越大，出块时间就越长，为了得到相对平均的出块时间，需要动态调整挖矿难度。<br>比特币每产生2016个区块调整一次挖矿难度，一个块10分钟，2016个块大概是两周的时间，而调整挖矿难度的这些逻辑都在代码中，当大多数诚实节点采用这个策略的时候整个网络就会自动遵循这个策略。</p>
<p>挖矿难度的计算公式如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">diffculty = difficulty_1_target / target</div></pre></td></tr></table></figure></p>
<p>此处的 difficulty_1_target 为一个常数，非常大的一个数字（ 2^(256-32)−1 ）。表示挖矿的初始难度，目标值越小，区块生成难度越大。</p>
<blockquote>
<p> 2^(256-32)−1 是比特币的初始难度，是前2016个块的难度。 </p>
</blockquote>
<p>这个难度被存储在比特币的区块头nBits字段中，当有恶意节点篡改这个策略时，挖矿产生的区块头的哈希值就会和诚实节点产生冲突，不会被接收，白白浪费了算力。</p>
<blockquote>
<p>因为策略不同，也就是nBits不同，恶意节点产生的区块哈希无法被诚实节点验证。</p>
</blockquote>
<h5 id="调整出块时间"><a href="#调整出块时间" class="headerlink" title="调整出块时间"></a>调整出块时间</h5><p>比特币系统中区块的生产速度是根据之前产生区块速度调整的，之前出块速度大于10分钟，则认为需要降低难度，则需要提高第一个公式中target的值，而target则通过如下公式计算；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">target  =  target  *  ( actual time  /  excepted time )</div></pre></td></tr></table></figure></p>
<p>actual time是实际产生区块的时间，excepted time是期望出块时间（2016块*10分钟），actual time有上下限，actual time最多8周，最小二分之一周。</p>
<h3 id="挖矿算法"><a href="#挖矿算法" class="headerlink" title="挖矿算法"></a>挖矿算法</h3><p>比特币中<code>nBits</code>标识了挖矿的难度，也就是说这个区块头进行SHA-256哈希算法后得到的bytes转换成数字后要小于这个难度，而SHA-256计算后的结果有256位，如果直接存储需要32个字节比较占用空间，所以采用了一种压缩算法。</p>
<h5 id="压缩算法"><a href="#压缩算法" class="headerlink" title="压缩算法"></a>压缩算法</h5><p><code>nBits</code>有4个字节32位，将SHA-256计算得到的值经过如下算法压缩到32位；</p>
<ol>
<li>将数字转换为 256 进制。</li>
<li>如果第一位数字大于 127（0x7f），则前面添加 0。</li>
<li>压缩结果中的第一位存放该256进制数的位数。</li>
<li>后面三个数存放该256进制数的前三位，如果不足三位，从后补零。</li>
</ol>
<p>举个例子，将十进制1000压缩;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">1. 1000转换256进制数，1000 = 3 * 256 + 232 = 3*256^(2-1) + 232*256^(1-1)</div><div class="line">2. 3小于127，不需要补0，跳过</div><div class="line">3. 从第一部看到1000转换成256位数有2位，压缩结果第一位应该存放2</div><div class="line">4. 因为只有两位，所以最后一位补0，得到存放的值为 [2, 3, 232, 0]十进制，转换十六进制 [0x02, 0x03, 0xe8, 0x00] 合并存储到nbits为 0x0203e800</div></pre></td></tr></table></figure></p>
<h5 id="难度计算"><a href="#难度计算" class="headerlink" title="难度计算"></a>难度计算</h5><p>在第一个公式中<code>difficulty_1_target</code>的值为 2^(256-32)-1,转换成256进制为；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF</div></pre></td></tr></table></figure></p>
<p>第一位大于0x7f，前面补0，变为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">00 FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF</div></pre></td></tr></table></figure></p>
<p>其长度等于 28+1=29 (0x1d)，且长度超过三位，无需补零，则压缩结果为：0x1d00FFFF，因为压缩存储容量只有才4个字节，前两字节已经被长度和添加的 00 所占用，只剩下2个字节来存储数字，这样后面的26个 FF 值被丢弃。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">T=0x00FFFF * 256^(0x1b-3) = 0x00000000FFFF0000000000000000000000000000000000000000000000000000</div></pre></td></tr></table></figure></p>
<p>比特币中的difficulty就是0x1d00FFFF，如果区块中的nBits为0x1d00FFFF则说明这个区块挖矿难度为最小挖矿难度1.</p>
<p>实际上专业的矿池程序会保留被截断的FF：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">00 FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF FF</div></pre></td></tr></table></figure></p>
<p>我们算一下比特币101799号区块的挖矿难度，通过区块链浏览器可以看到101799号区块的nBits为0x1b0404cb<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D = 0x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF / 0x00000000000404CB000000000000000000000000000000000000000000000000 = 16307.669773817162 (pdiFF)</div></pre></td></tr></table></figure></p>
<p><code>pdiFF</code>也被称为矿池难度。</p>
<h3 id="算力"><a href="#算力" class="headerlink" title="算力"></a>算力</h3><p>为了找到符合条件的值在挖矿的时候需要不断的调整区块头中Nonce的值，但是又会有一个问题，在比特币中Nonce的值是32位的，如果挖矿难度太大，就算穷尽Nonce的所有可能还是不能算出符合条件的值。</p>
<h5 id="铸币交易"><a href="#铸币交易" class="headerlink" title="铸币交易"></a>铸币交易</h5><p>在一个区块产生的时候，会有一个铸币交易（coinbase），也就是矿工为自己铸币，产生新的比特币。</p>
<p>铸币交易没有UTXO输入，只有输出指向自己的比特币地址，当挖矿成功，这个区块被网络接收的时候，新产生的币就转移到这个矿工地址了。</p>
<p>看一下铸币交易包含的字段；</p>
<ul>
<li>transaction hash：“交易哈希”字段32个字节全部填充0（因为其没有UTXO输入）；</li>
<li>ouput index：“交易输出索引”字段全部填充0xFF(十进制的255)；</li>
<li>coinbase data：coinbase数据长度最小2字节，最大100字节。除了开始的几个字节外，矿工可以任意使用coinbase的其他部分，随意填充任何数据。以创世块为例，中本聪在coinbase中填入了这样的数据“The Times 03/Jan/ 2009 -Chancellor on brink of second bailout for banks“；</li>
<li>coinbase data size：coinbase数据大小；</li>
<li>sequence number：现在未使用，设置为0xffffffff</li>
</ul>
<p>可以看到铸币交易的coinbase data字段是我们可以控制的，当Nonce不能满足挖矿难度的时候，我们可以通过调整coinbase data字段，从而影响区块头的默克尔树根的值，提供更多的可能来满足挖矿难度的要求。</p>
<h5 id="算力单位"><a href="#算力单位" class="headerlink" title="算力单位"></a>算力单位</h5><p>通过上面的流程，进行一次可能的挖矿尝试被称为<code>H</code>。<br>1 H/s   = 每秒可执行一次哈希运算。<br>1 KH/s = 每秒1,000哈希（一千次）。<br>1 MH/s = 每秒1,000,000次哈希（百万次）。<br>1 GH/s = 每秒1,000,000,000次哈希（十亿次）。<br>1 TH/s = 每秒1,000,000,000,000次哈希（万亿次）。<br>1 PH/s = 每秒1,000,000,000,000,000次哈希。<br>1 EH/s = 每秒1,000,000,000,000,000,000次哈希。</p>
<h3 id="挖矿收益"><a href="#挖矿收益" class="headerlink" title="挖矿收益"></a>挖矿收益</h3><p>矿机挖矿的时候就会出现很长的时间找不到符合条件的哈希值，如果找不到哈希值不能打包区块就没有收益，显然对矿工十分不友好，但是如果挖到就像中彩票一样获得非常丰厚的回报。</p>
<h5 id="矿池"><a href="#矿池" class="headerlink" title="矿池"></a>矿池</h5><p>为了避免单个矿工挖矿收益的不稳定性，就出现了矿池，矿池集合了大量的矿工，平均挖矿的收益，避免了挖矿收益的不稳定性。<br>矿池组织大量的矿工挖矿面临很重要的一个问题就是如何把高难度计算哈希的任务拆解成相对简单的任务，发送给单个矿工，回顾之前挖矿难度的计算，可以简单的认为前面0的多少表明了挖矿的难易。<br>0越多，挖矿难度越高，为了降低挖矿难度我们就要增加挖矿哈希0的数量，举个例子<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">假设挖矿目标值  0x000abc，只要满足这个值就可以打包区块获得挖矿收益；</div><div class="line">降低挖矿难度为 0x001abc，发送给矿工，矿工只要计算区块头满足这个相对低一点的难度就可以得到一个分片（shared），但是单个矿工挖到这个简单难度的块是无法发布到整个网络中的，但是矿池可以把这个分片记录下来，作为以后给这个矿工奖励的凭证。</div><div class="line">0x001abc是0x000abc的子集，只要子集足够多总有一个会满足目标值。</div><div class="line">当有一个矿工挖出一个满足目标值之后就可以获得挖矿收益，而挖矿就可以根据矿工分片多少来获得收益。</div><div class="line"></div><div class="line">矿工收益 = 挖矿收益 / 挖到的分片数量</div></pre></td></tr></table></figure></p>
<p>但是现在还有一个问题没有解决，单个矿工挖到目标值以后如果私吞收益，私自广播区块怎么办？</p>
<p>矿池有集中托管式的，也有分布式的。</p>
<ul>
<li>集中托管式矿池，矿工可以把挖矿的机器托管给矿池，由矿池统一操作维护，只需要支付一些电费管理费即可，这样就避免了私自广播。</li>
<li>分布式矿池，矿工将机器自行管理，通过矿池协议从网络连接矿池即可，这样就会出现私自广播的可能。</li>
</ul>
<p>回顾一下铸币交易<code>coinbase</code>，可以看到有<code>output</code>字段，UTXO模型中币的来源都是上一个交易的output，所以可以把铸币交易的output字段设置为矿池的地址，然后随机生成一些<code>coinbase data</code>的填充后生成区块头的默克尔树，最后发由矿工去尝试目标值。</p>
<p>通过这样的方式，即使矿工找到满足条件的哈希值，铸币交易的地址也是矿池的地址，私自广播区块没有任何收益，如果调整铸币交易的地址，这样又回到了独立挖矿的场景。</p>
<h5 id="全网算力"><a href="#全网算力" class="headerlink" title="全网算力"></a>全网算力</h5><p>如果要获知全网算力，可以通过出块时间，挖矿难度大致反推出全网算力。</p>
<h3 id="区块确认"><a href="#区块确认" class="headerlink" title="区块确认"></a>区块确认</h3><p>当一个区块产生之后，它不是立即可信的，网络上的节点总是相信最长的区块链，当一条交易记录被打包进一个区块之后，就有了一个确认，而这个区块所在的链后面被再加入一个区块，就是第二个确认，如此下去，一个交易有了6个确认，我们就认为这个交易已经确定了，会被永远记录在区块链中。<br>为什么是6个确认呢？因为每一个确认就是一个挖矿过程，需要大量的工作量证明，因此，这6个区块被同一个矿工创建的可能性微乎其微（可以说是不可能），因此矿工伪造交易也基本不可能。</p>
<p>由于比特币的区块平均产生时间是10分钟，所以一个交易要1小时左右才能保证成功（最快），不过也不是所有的系统都这样认为，有些网站在接受比特币支付时，认为4个确认就可以给客户发货了，区块确认越多则越难被逆转。</p>
<h3 id="区块广播"><a href="#区块广播" class="headerlink" title="区块广播"></a>区块广播</h3><p>在区块链中，为了尽快收到其他节点的信息，节点间并不是直接传递区块信息的。<br>节点向附近节点发送一个<code>Inv</code>消息，Inv消息中包含已经被发送者（sender）接收并验证过的“交易记录的哈希”、以及“区块哈希”。接收者（receiver）收到Inv消息后，如果他还尚未从其他节点收到过相同的信息，他会发送一个getdata消息给发送者，要求得到交易记录及区块哈希包含的具体信息。此时，区块和交易记录的信息才会进行整体传递。<br>其中<code>Inv</code>消息结构如下；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">type MsgInv struct &#123;</div><div class="line">    InvList []*InvVect</div><div class="line">&#125;</div><div class="line"></div><div class="line">type InvVect struct &#123;</div><div class="line">    Type InvType // Type of data</div><div class="line">    Hash chainhash.Hash // Hash of the data</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;比特币网络中，源源不断的收到交易，需要节点不断的打包这些交易，而网络中的所有节点都是对等的，如何判断谁可以打包这些交易，如何避免重复打包这些交易呢？&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="比特币" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E6%AF%94%E7%89%B9%E5%B8%81/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="比特币" scheme="qyuan.top/tags/%E6%AF%94%E7%89%B9%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>UTXO模型和Account模型对比</title>
    <link href="qyuan.top/2019/11/04/utxo-account/"/>
    <id>qyuan.top/2019/11/04/utxo-account/</id>
    <published>2019-11-04T13:04:52.000Z</published>
    <updated>2019-11-04T12:08:06.188Z</updated>
    
    <content type="html"><![CDATA[<p>目前主流的区块链采用<code>UTXO（Unspent Transaction Output）</code>和<code>账户（Account）</code>模型来组织交易，其中比特币采用UTXO模型，以太坊采用Account模型。</p>
<a id="more"></a>
<h3 id="UTXO-模型"><a href="#UTXO-模型" class="headerlink" title="UTXO 模型"></a>UTXO 模型</h3><p>UTXO全名是Unspent Transaction Outputs，未花费交易输出，举个例子；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/utxo_account/1.png?raw=true" width="100%" height="100%"></p>
<p>假设A挖出了区块1，获得了10个BTC，这个时候在UTXO模型中，A的余额是10，同时A向B和C分别转账5个比特币，这两笔交易被打包到区块2中，这个时候UTXO模型中，B和C的余额分别是5，当查看区块4打包的交易以后，发现这时的UTXO模型中显示，G和C有2.5个BTC，H有5个BTC。</p>
<h5 id="凑输入和找零"><a href="#凑输入和找零" class="headerlink" title="凑输入和找零"></a>凑输入和找零</h5><p>UTXO有个性质就是一个交易的输入必须是另一个交易的输出，这就导致了一个问题，在上图中，地址F如果只需要2.5个BTC怎么办？<br>F的来源只可能B，C但是无论我们怎么组合都无法满足H只需要2.5个BTC的需求。这个时候就需要将一次转账拆分成转向两个地址，其中地址C’还由C控制，这样就完成了一次找零。</p>
<blockquote>
<p>C’被称为找零地址。</p>
</blockquote>
<p>如果不设置找零地址，其中的差额将会被矿工当做手续费扣除。</p>
<p>凑整的过程与找零刚好相反，地址H的输入就是一个凑整的过程。</p>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><ul>
<li>除了了BTC产生的交易外每一笔交易的输出都是另一笔交易输入；</li>
<li>如果丢失私钥丧失账户的控制权后，UTXO会一直保存这个账户的余额，因为没有输出；</li>
<li>随着比特币的碎片化和账户私钥的丢失，UTXO模型会越来越膨胀；</li>
<li>验证一笔交易的余额是否足够需要向上追溯；</li>
<li>通过UTXO模型可以一定程度上避免双花攻击；</li>
<li>UTXO通过找零设置新地址增加了一定的隐私性，因为除了你本人是不知道哪个地址是找零地址，哪个是收款地址。</li>
</ul>
<h3 id="Account模型"><a href="#Account模型" class="headerlink" title="Account模型"></a>Account模型</h3><p>相比较UTXO模型Account模型更加符合我们的认知，类似传统的银行账户，以太坊采用账户模型主要是为了支持智能合约，对于智能合约来说需要一个相对稳定的身份。<br>举个例子，当我们签订一份合同，希望双方的身份很明确，但是在UTXO模型中，身份可以通过找零地址变更，当合同出现问题很难明确权责。</p>
<p>以太坊作为智能合约操作平台，将账户划分为两类：外部账户（EOAs）和合约账户（contract account）</p>
<h5 id="外部账户"><a href="#外部账户" class="headerlink" title="外部账户"></a>外部账户</h5><p>外部账户(external owned accouts)是由私钥创建，具有以下特点；</p>
<ul>
<li>拥有以太余额；</li>
<li>能发送交易，包括转账和执行合约代码；</li>
<li>被私钥控制；</li>
<li>没有相关的可执行代码；</li>
</ul>
<h5 id="合约账户"><a href="#合约账户" class="headerlink" title="合约账户"></a>合约账户</h5><p>含有合约代码的账户， 被外部账户或者合约创建，合约在创建时被分配到一个账户地址， 用于存储合约代码以及合约部署或执行过程中产生的存储数据，其具有如下特点；</p>
<ul>
<li>不能发送交易；</li>
<li>合约账户接收到外部账户发来的交易以后可以通过Message调用其他合约账户；</li>
<li>合约账户存储了合约代码和合约状态；</li>
</ul>
]]></content>
    
    <summary type="html">
    
      对比比特币的UTXO模型和以太坊的Account模型
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
  </entry>
  
  <entry>
    <title>默克尔证明</title>
    <link href="qyuan.top/2019/11/01/merkle-proof/"/>
    <id>qyuan.top/2019/11/01/merkle-proof/</id>
    <published>2019-11-01T13:18:39.000Z</published>
    <updated>2019-11-01T08:33:39.795Z</updated>
    
    <content type="html"><![CDATA[<p>假设有这样一种场景需要用到比特币支付，支付完成以后我需要向对方证明这笔交易已经写到区块中了，比较容易想到的办法就是拿到打包交易的对应区块，然后对比区块中的所有交易来确认是否已经被打包其中。</p>
<a id="more"></a>
<p>但是在比特币或者以太坊的场景下，一个区块大概有两三千笔交易，一个交易又包含若干字段，如果逐一比较交易不仅速度慢，而且不安全，因为拿单一的区块你无法知道拿到的块的真伪。</p>
<p>而默克尔证明提供了一种仅需链中全量区块头信息就可以证明交易是否存在某一区块中的方法。</p>
<blockquote>
<p>全量保存区块头是为了保证安全性，而且区块头很小，非常适合在一些移动设备存储。</p>
</blockquote>
<h5 id="默克尔证明"><a href="#默克尔证明" class="headerlink" title="默克尔证明"></a>默克尔证明</h5><p>默克尔证明基于默克尔树。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/merkleproof/1.png?raw=true" width="100%" height="100%"></p>
<p>如果我们知道了根哈希，也就是紫色的这个节点包含的值，需要证明红色的节点包含的<code>Peach</code>是否在这个集合中，仅需要提供绿色节点包含的值就可以。<br>我们可以计算出<code>Peach</code>的哈希值，然后依次与绿色节点包含的哈希值两两计算哈希，最终就可以得到根哈希，根哈希一致则证明<code>Peach</code>在这个区块中。</p>
<h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ul>
<li>无需知道其他节点的值是什么就可以证明特定节点是否在集合中。</li>
<li>仅存储默克尔证明消耗很小的空间。</li>
<li>判断一笔交易是否在区块中的消耗很低。</li>
</ul>
<h5 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h5><p>轻节点只包含区块头，也就是只有交易树的根哈希值，当A需要向轻节点证明一笔交易已经打包到指定区块时，只需要提供这笔交易和对应路径上的哈希值即可，这样轻节点就可以在不保存区块体的情况下证明了这笔交易已经上链不可更改了。</p>
]]></content>
    
    <summary type="html">
    
      默克尔证明
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>P2P网络核心技术之Gossip协议</title>
    <link href="qyuan.top/2019/10/25/gossip/"/>
    <id>qyuan.top/2019/10/25/gossip/</id>
    <published>2019-10-25T13:16:07.000Z</published>
    <updated>2019-10-25T06:27:57.467Z</updated>
    
    <content type="html"><![CDATA[<p>在Hyperledger Fabric中，节点间同步数据采用的是<code>Gossip</code>协议，当节点因为异常缺少账本数据时，可以通过<code>Gossip</code>协议从邻近的节点获得账本数据，保证集群中节点账本的一致性。</p>
<a id="more"></a>
<h3 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h3><p>Gossip是流言的意思，很好的诠释了协议的过程，协议传输数据也是采用了类似流言传播的方式在集群中扩散。</p>
<p>Gossip是一种去中心化思路的分布式协议，解决集群中的数据传播和状态一致性的问题。</p>
<h5 id="协议流程"><a href="#协议流程" class="headerlink" title="协议流程"></a>协议流程</h5><ul>
<li>节点A周期性的选择相邻的k个节点，并且向这K个节点发送自身存储的数据；</li>
<li>K个节点接收到A发送过来的数据后，发现自身没有则存储下来，如果有则丢掉，并且重复节点A的过程。</li>
</ul>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/gossip/1.gif?raw=true" width="90%" height="50%"></p>
<p>在节点A向节点K发送数据的时候有三种方式；</p>
<ul>
<li><code>push</code>模式，节点A将数据（key，version，value）推送给K，K更新version比自己新的数据。</li>
<li><code>pull</code>模式，节点A将数据（key，version）推送给K，K将本地version比A新的数据推送给A。</li>
<li><code>push/pull</code>模式，先采用push模式更新K，然后采用pull模式更新A。</li>
</ul>
<p>push模式需要通信一次，pull模式需要两次，pull/push模式需要通信三次，而从最终一致性的收敛速度也与通信次数成正比。将消息传播到所有节点的时间复杂度为log(n)。  </p>
<h5 id="Gossip缺陷"><a href="#Gossip缺陷" class="headerlink" title="Gossip缺陷"></a>Gossip缺陷</h5><ul>
<li><p>消息的延迟，由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景。</p>
</li>
<li><p>消息冗余，Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。而且，由于是定期发送，因此，即使收到了消息的节点还会反复收到重复消息，加重了消息的冗余。</p>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      gossip网络协议
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="P2P网络" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/P2P%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>以太坊区块结构</title>
    <link href="qyuan.top/2019/10/20/block/"/>
    <id>qyuan.top/2019/10/20/block/</id>
    <published>2019-10-20T12:56:12.000Z</published>
    <updated>2019-11-01T07:56:16.135Z</updated>
    
    <content type="html"><![CDATA[<p>区块就是交易的集合，公链链或者联盟链将交易打包成区块以后会进行持久化存储。</p>
<a id="more"></a>
<p>看一下经典的以太坊区块结构。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/block/1.png?raw=true" width="100%" height="50%"></p>
<p>从上图可以看到，区块由两部分组成，分别是区块头（header）和区块体（body）两部分。</p>
<h3 id="区块头（header）"><a href="#区块头（header）" class="headerlink" title="区块头（header）"></a>区块头（header）</h3><p>区块头存储了区块的元信息，用来对区块内容进行一些标识，校验，说明等。区块头里字段分为两部分区块头和区块体。</p>
<h5 id="通用字段"><a href="#通用字段" class="headerlink" title="通用字段"></a>通用字段</h5><ul>
<li>ParentHash： 父区块的哈希值。</li>
<li>Root：世界状态的哈希，stateDB的RLP编码后的哈希值。</li>
<li>TxHash（transaction root hash）：交易字典树的根哈希，由本区块所有交易的交易哈希算出。</li>
<li>ReceptHash：收据树的哈希。</li>
<li>Time：区块产生出来的Unix时间戳。</li>
<li>Number：区块号。</li>
<li>Bloom：布隆过滤器，快速定位日志是否在这个区块中。</li>
</ul>
<h5 id="公链场景"><a href="#公链场景" class="headerlink" title="公链场景"></a>公链场景</h5><ul>
<li>Coinbase：挖出这个块的矿工地址，因为挖出块所奖励的ETH就会发放到这个地址。</li>
<li>Difficulty：当前工作量证明（Pow）算法的复杂度。</li>
<li>GasLimit: 每个区块Gas的消耗上线。</li>
<li>GasUsed：当前区块所有交易使用的Gas之和。</li>
<li>MixDigest: 挖矿得到的Pow算法证明的摘要，也就是挖矿的工作量证明。</li>
<li>nonce：挖矿找到的满足条件的值。</li>
<li>Uncle：叔块是和以太坊的共识算法相关。</li>
</ul>
<p>一般而言一个类以太坊的联盟链是需要上面介绍的通用字段的，但是也不绝对，还可能与选择的共识算法，隐私保护策略，设计偏好有关。</p>
<h3 id="区块体（Body）"><a href="#区块体（Body）" class="headerlink" title="区块体（Body）"></a>区块体（Body）</h3><p>区块体包括这个区块打包的所有交易，在一些链的设计中，并不像以太坊区分header和body，而是整合在一起。</p>
<h3 id="区块存储"><a href="#区块存储" class="headerlink" title="区块存储"></a>区块存储</h3><p>以太坊在存储区块的时候，区块头和区块体其实是分开存储的，其实也很容易理解，分开存储可以提供更多的灵活性，比如不用保存全部区块数据的轻节点。</p>
<h5 id="区块头存储"><a href="#区块头存储" class="headerlink" title="区块头存储"></a>区块头存储</h5><p>以太坊通过如下方式将区块头转换成键值对存储在LevelDB中；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">headerPrefix + num + hash  -&gt; rlp(header)</div><div class="line"></div><div class="line">Tips: num是以大端序的形式转换成bytes的，其中headerPrefix的值是 []byte(&quot;h&quot;)</div></pre></td></tr></table></figure></p>
<h5 id="区块体存储"><a href="#区块体存储" class="headerlink" title="区块体存储"></a>区块体存储</h5><p>区块体的存储方式也是类似；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bodyPrefix + num + hash -&gt; rlp(block)</div><div class="line"></div><div class="line">Tips: num是以大端序的形式转换成bytes的，其中bodyPrefix的值是[]byte(&quot;b&quot;)</div></pre></td></tr></table></figure></p>
<h3 id="潜在问题"><a href="#潜在问题" class="headerlink" title="潜在问题"></a>潜在问题</h3><p>假设在一个联盟链的场景下，采用了BFT类的算法，有一个重量级的业务跑在上面，日积月累产生了大量的数据，是否会出现LevelDB的读写性能大幅下降拖慢系统的响应速度？单机存储无法满足需要？存储了大量的不会使用的历史数据？</p>
<p>在联盟链的场景下，由于共识速度的提升，导致出块速度也大幅提升，原本在公链场景下不存在的区块写入瓶颈，现在反而成了拖慢系统运行速度的重要因素了。</p>
<p>观察一下区块数据的存储就可以发现下面的这些特点；</p>
<ul>
<li>区块数据只会增加；</li>
<li>无需对历史区块进行修改；</li>
<li>无需对区块数据进行复杂操作，比如聚合，运算等；</li>
</ul>
<p>归纳一下就是顺序写，随机读和迭代（Iterator），针对这些特点Hyperledger Fabric设计了基于文件的存储方式，在Fabric中区块数据是以一个个文件的形式存在。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">chains</div><div class="line">  |----mychannel</div><div class="line">  |----|----blockfile_000000</div><div class="line">index</div><div class="line">  |----000001.log</div><div class="line">  |----CURRENT</div><div class="line">  |----LOCK</div><div class="line">  |----LOG</div><div class="line">  |----MANIFEST-000000</div></pre></td></tr></table></figure>
<p>其中blockfile_000000是区块数据，index则是索引游标等元信息，这种方式速度很快，方便做数据归档，也可以避免像LevelDB等数据库数据越写越慢的问题，主流联盟链都是采用类似的方案。</p>
]]></content>
    
    <summary type="html">
    
      以太坊区块结构
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>Merkle Patricia Tree (MPT) 树详解之实际应用（三）</title>
    <link href="qyuan.top/2019/10/12/mpt-3/"/>
    <id>qyuan.top/2019/10/12/mpt-3/</id>
    <published>2019-10-12T13:57:38.000Z</published>
    <updated>2019-10-27T11:16:40.266Z</updated>
    
    <content type="html"><![CDATA[<p>以太坊区块中有三颗MPT树，分别是状态树，交易树，收据树 ，分别存储了以太坊中的世界状态，本区块的交易，本区块的交易回执，其中交易和交易回执是一一对应的。</p>
<a id="more"></a>
<h3 id="状态树"><a href="#状态树" class="headerlink" title="状态树"></a>状态树</h3><p>每次生成一个新的区块，以太坊状态发生改变后并不会去修改原来的MPT树，而是会新建一些分支，如下图所示；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt3/1.png?raw=true" width="110%" height="50%"></p>
<h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ul>
<li>当一个账户的余额发生改变后，对应路径的哈希也发生了变化，然后自底而上的更新对应路径上的哈希值，直至Satet Root，这样可以计算最少的哈希次数。</li>
<li>以太坊中的全节点维护的是增量的MPT状态树，因为每次一个区块对世界状态的修改都只是很小的一部分，增量修改既有利于区块回滚，又可以节约开销。</li>
<li>在以太坊中区块临时分叉很普遍，但是由于以太坊智能合约的复杂性，如果不记录原始状态，很难根据合约代码回滚状态。</li>
</ul>
<h3 id="收据树"><a href="#收据树" class="headerlink" title="收据树"></a>收据树</h3><p>以太坊在智能合约执行时会产生一个交易回执（Receipt）记录了此笔交易的执行结果，交易信息和区块信息。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt3/2.png?raw=true" width="90%" height="50%"></p>
<p>当查询轻节点查询通过布隆过滤器找到交易后，为了避免误识，还会再次查询回执来避免误识。</p>
<h3 id="交易树"><a href="#交易树" class="headerlink" title="交易树"></a>交易树</h3><p>交易树的作用是提供了交易的默克尔证明，证明某个交易被打包到某个区块里，轻节点不用存储区块体仅根据提供的默克尔证明就可以快速判断交易是否已经被打包。</p>
<h3 id="三颗树的差异"><a href="#三颗树的差异" class="headerlink" title="三颗树的差异"></a>三颗树的差异</h3><p>交易树和收据树只依赖当前的区块，而状态树是把链上所有状态都包含进去，交易树和收据树是独立的，状态树会共享树的节点。</p>
<p>为什么状态树要包含所有链上所有的状态呢？</p>
<p>举个例子，当一笔转账操作的发起时，需要判断发起账户是否有足够的ETH来完成这笔转账，这个时候要通过查找状态树查看对应账户的状态，但是如果为了节约空间，只保存了当前区块账户的状态，就需要逐块查找，非常影响性能，甚至这个转账交易的发起者都不存在，是一个恶意操作。</p>
]]></content>
    
    <summary type="html">
    
      以太坊Merkle Patricia Tree（MPT）树详解，如何数据持久化，如何存储。
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Merkle Patricia Tree (MPT) 树详解之数据持久化（二）</title>
    <link href="qyuan.top/2019/10/12/mpt-2/"/>
    <id>qyuan.top/2019/10/12/mpt-2/</id>
    <published>2019-10-12T13:56:38.000Z</published>
    <updated>2019-10-12T04:07:10.587Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="http://qyuan.top/2019/10/08/mpt/">「Merkle Patricia Tree (MPT) 树详解之数据结构（一）」</a>介绍了以太坊MPT树的结构，但是如何将MPT树持久化呢？以太坊采用LevelDB做数据库，如何将MPT树的节点映射成键值对存储到LevelDB呢？</p>
<a id="more"></a>
<p>以太坊的MPT树提供了三种不同的编码方式来满足不同场景的不同需求，三种编码方式为；</p>
<ul>
<li>Raw编码（原生字符）</li>
<li>Hex编码（扩展16进制编码）</li>
<li>Hex-Prefix编码（16进制前缀编码）</li>
</ul>
<p>三者的关系如下图所示，分别解决的是MPT对外提供接口的编码，在内存中的编码，和持久化到数据库中的编码。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt2/1.jpg?raw=true" width="80%" height="80%"></p>
<h3 id="Raw编码"><a href="#Raw编码" class="headerlink" title="Raw编码"></a>Raw编码</h3><p>MPT对外提供的API采用的就是Raw编码方式，这种编码方式不会对key进行修改，如果key是“foo”, value是”bar”，编码后的key就是[“f”, “o”, “o”]。</p>
<p>假设我们要把<code>a</code>作为key放入MPT树，key可以直接用<code>a</code>的ASCII表示97就可以了。</p>
<h3 id="Hex编码"><a href="#Hex编码" class="headerlink" title="Hex编码"></a>Hex编码</h3><p>可以发现采用Raw编码以后，从a-z一共26个字母，如果采用<code>分支节点（BranchNode）</code>存储的话需要26个空间，如果再加上0-9一共10个数字和一个value，总共需要37个空间，以太坊的开发者权衡了一下觉得太多了，于是就改良了编码方式，有了Hex编码。</p>
<p>以太坊先定义了一个新单位<code>nibble</code>，一个<code>nibble</code>表示4个bit，0.5个byte。然后按照如下规则编码；</p>
<ul>
<li>将Raw输入的每个字符（1byte）拆分成2个nibble，前4位和后4位各一个nibble；</li>
<li>将每个nibble扩展为1个byte（8个bit）；</li>
<li>然后分别将Raw编码后的十六进制结果的每个<code>b</code>进行如下操作<ul>
<li>b / 16；</li>
<li>b % 16；</li>
</ul>
</li>
</ul>
<p>有疑惑的话看一下这个例子就懂了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">a的ASCII编码为99（十进制），转换十六进制为63</div><div class="line">采用Hex编码</div><div class="line">[0] = 61 / 16 = 3</div><div class="line">[1] = 61 % 16 = 13</div><div class="line">编码后的结果 [3, 13]</div><div class="line"></div><div class="line">在举个例子</div><div class="line">输入&quot;cat&quot;，Raw编码后 [63, 61, 74]</div><div class="line">63 / 16  = 3</div><div class="line">63 % 16 = 15</div><div class="line">61 / 16 = 3</div><div class="line">61 % 16 = 13</div><div class="line">74 / 16 = 4</div><div class="line">74 % 16 = 10</div><div class="line">编码后的结果 [3，15，3，13，4，10]</div></pre></td></tr></table></figure></p>
<p>树的最后一位value是一个标识符，如果存储的是真实的数据项，即该节点是叶子节点，则在末尾添加一个ASCII值为16的字符作为终止标识符。添加后的结果是<code>[3，15，3，13，4，10, 16]</code></p>
<p>采用Hex编码以后，可以看到原本需要的37个空间存储的消耗都被压缩到了17个空间，横向压缩，但是增加了纵向空间的消耗，是一种工程的妥协。根据Key的数量多少，压缩与否各有优劣。</p>
<h3 id="HP编码（Hex-Prefix-Encoding-16进制前缀编码）"><a href="#HP编码（Hex-Prefix-Encoding-16进制前缀编码）" class="headerlink" title="HP编码（Hex-Prefix Encoding 16进制前缀编码）"></a>HP编码（Hex-Prefix Encoding 16进制前缀编码）</h3><p>前面介绍的Hex编码后的数据是在内存中的，如果要对Hex编码后的数据进行持久化，就会发现一个问题，我们对原数据进行了扩展，本来1个byte的数据被我们变成了2个byte，显然这对于存储来说是不可接受的，于是就又有了HP编码。</p>
<p>HP编码的过程如下；</p>
<ul>
<li>输入key（Hex编码的结果）如果有标识符，则去掉这个标识符。</li>
<li>key的头部填充一个nibble，填充的规则如下<ul>
<li>如果key的nibble长度是偶数则最后一位0</li>
<li>如果key的nibble长度是奇数则最后一位1</li>
<li>如果key是<code>扩展节点</code>则倒数第二位是0</li>
<li>如果key是<code>叶子节点</code>则倒数第二位是1</li>
</ul>
</li>
</ul>
<p>例子：nibble长度是奇数的扩展节点填充为0001。</p>
<p>举个例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&quot;cat&quot;经过HP编码后的结果 [3，15，3，13，4，10, 16]</div><div class="line">再用HP编码</div><div class="line">1. 去掉16，同时表明这个是叶子节点。</div><div class="line">2. 叶子节点，nibble数量是奇数个，这两个条件得出需要填充的值为 0010 0000</div><div class="line">3. 将HP编码后的结果用二进制表示 [0010, 0000，0011, 1111, 0011, 1101, 0100, 1010]</div><div class="line">4. 将HP编码后的结果合并成byte，为[00100000, 00111111, 00111101, 01001010]转换为十进制是[32, 63, 61, 74]</div></pre></td></tr></table></figure></p>
<p>相较与cat的Raw编码，经过上面的Hex编码和HP编码，既可以能在内存中构建出MPT树，又可以尽可能减小存储所占用的空间，不得不说以太坊设计的巧妙。</p>
<h3 id="安全的MPT"><a href="#安全的MPT" class="headerlink" title="安全的MPT"></a>安全的MPT</h3><p>在上面介绍三种编码并没有解决一个问题，如果我们的key非常的长，会导致树非常的深，读写性能急剧的下降，如果有人不怀好意设计了一个独特的key甚至是可以起到DDOS攻击的作用，为了避免上面的问题，以太坊对key进行了一个特别的操作。</p>
<p>将所有的key都进行了一个<code>keccak256(key)</code>的操作，在<a href="http://qyuan.top/2019/09/24/evm-2/">「EVM深度分析之数据存储(二)」</a>中也可以看到EVM持久化的数据也都进行了哈希操作，这样就可以避免上面问题的发生。</p>
<h3 id="持久化MPT"><a href="#持久化MPT" class="headerlink" title="持久化MPT"></a>持久化MPT</h3><p>MPT树节点Key的三种编码形式，但是这三种编码都是对key进行的操作，最终持久化到LevelDB中是k-v的形式，还需要对value进行处理。</p>
<p>在以太坊存储键值对之前会采用RLP编码对键值对进行转码，（RLP编码可以参照之前的文章<a href="http://qyuan.top/2019/05/20/rlp/">「以太坊RLP编码」</a>），将键值对编码后作为value，计算编码后数据的哈希（keccak256）作为key，存储在levelDB中。</p>
<p>在具体的实现中，为了避免出现相同的key，以太坊会给key增加一些前缀用作区分，比如合约中的MPT树，会增加合约地址，区块数据会增加表示区块的字符和区块号。<br>MPT树是以太坊非常非常核心的数据结构，在存储区块，交易，交易回执中都有用到，下图展示了MPT树的全貌，可以再感受一下MPT树的精巧</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt2/2.png?raw=true" width="80%" height="80%"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>其实随着数据的膨胀，LevelDB的读写速度都会变慢，这个是LevelDB实现导致的，目前也有一些针对性的优化。还有一种和MPT树非常相近的另一种数据结构<a href="http://qyuan.top/2019/04/18/BucketTree/">BucketTree</a>，也可以实现相同的功能，各有优劣。</p>
]]></content>
    
    <summary type="html">
    
      以太坊Merkle Patricia Tree（MPT）树详解，如何数据持久化，如何存储。
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Merkle Patricia Tree (MPT) 树详解之数据结构（一）</title>
    <link href="qyuan.top/2019/10/08/mpt/"/>
    <id>qyuan.top/2019/10/08/mpt/</id>
    <published>2019-10-08T13:55:30.000Z</published>
    <updated>2019-10-25T08:13:45.438Z</updated>
    
    <content type="html"><![CDATA[<p>在之前的EVM系列的文章中，其实一直有一个问题没有解决，那就是Storage持久化的数据最终是以什么样的形式，保存在哪里？数以万计的合约有数以万计的storage变量，这些变量如何快速的读写？</p>
<a id="more"></a>
<h3 id="字典树（Trie）"><a href="#字典树（Trie）" class="headerlink" title="字典树（Trie）"></a>字典树（Trie）</h3><p>Trie又称前缀树或字典树，是一种有序多叉树。下图是一颗典型的前缀树；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt/1.png?raw=true" width="80%" height="80%"></p>
<p>图中前缀树存储了一些字符串，蓝色的是关键字，存储的字符串由关键字组成。存储了”a”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”。<br>前缀树有这些特点；</p>
<ul>
<li>根节点不包含字符，其他节点各包含一个字符；</li>
<li>关键路径节点的字符连接起来为该节点所存储的数据；</li>
</ul>
<blockquote>
<p>关键路径就是每个节点有一个标志位，用来标记这个节点是否作为构成数据的一部分，上图中的，t, e 节点就不是关键路径。</p>
</blockquote>
<p>Trie的核心思想就是用空间换时间，利用公共前缀缩小要比较的范围来达到快速查找的目的。</p>
<h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>插入和查询的效率都很高，都是O(m)，m是插入或查询字符串的长度。</li>
<li>可以对数据按照字典序排序。</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>空间消耗的比较大。</li>
</ul>
<h5 id="典型场景"><a href="#典型场景" class="headerlink" title="典型场景"></a>典型场景</h5><ul>
<li>但词频次统计。</li>
<li>字符串匹配。</li>
<li>字符串字典序排序。</li>
<li>前缀匹配，比如一些搜索框的自动提示。</li>
</ul>
<h3 id="压缩字典树"><a href="#压缩字典树" class="headerlink" title="压缩字典树"></a>压缩字典树</h3><p>压缩字典树在字典树的基础之上做了一些优化，具体可以看下图；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt/2.jpeg?raw=true" width="80%" height="80%"></p>
<p>图中黑色的是关键路径，存储了字符串”abc”和”d”，但是明显可以看到压缩后的前缀树占用了更小的空间。</p>
<h3 id="默克尔树（Merkle-tree）"><a href="#默克尔树（Merkle-tree）" class="headerlink" title="默克尔树（Merkle tree）"></a>默克尔树（Merkle tree）</h3><p>默克尔树首先计算叶子节点的hash值，然后将相邻两个节点的哈希进行合并，合并完成后计算这个字符串的哈希值，直到根节点为止，如果是单个节点，可以复制单节点的哈希，然后合并哈希再重复上面的过程。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt/3.png?raw=true" width="80%" height="80%"></p>
<h5 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h5><p>可以高效安全的验证数据结构的内容。</p>
<h5 id="典型场景-1"><a href="#典型场景-1" class="headerlink" title="典型场景"></a>典型场景</h5><p>p2p网络分块下载文件的时候，快速校验下载到的数据是否完整，是否遭到破坏。</p>
<h3 id="默克尔帕特里夏树（Merkle-Patricia-Tree）"><a href="#默克尔帕特里夏树（Merkle-Patricia-Tree）" class="headerlink" title="默克尔帕特里夏树（Merkle Patricia Tree）"></a>默克尔帕特里夏树（Merkle Patricia Tree）</h3><p>MPT树结合了字典树和默克尔树的优点，在压缩字典树中根节点是空的，而MPT树可以在根节点保存整棵树的哈希校验和，而校验和的生成则是采用了和默克尔树生成一致的方式。<br>以太坊采用MPT树来保存，交易，交易的收据以及世界状态，为了<code>压缩整体的树高，降低操作的复杂度</code>，以太坊又对MPT树进行了一些优化。将树节点分成了四种；</p>
<ul>
<li>空节点（hashNode）</li>
<li>叶子节点（valueNode）</li>
<li>分支节点（fullNode）</li>
<li>扩展节点（shortNode）</li>
</ul>
<p>通过以太坊黄皮书中很经典的一张图，来了解不同节点的具体结构和作用</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/mpt/4.png?raw=true" width="80%" height="80%"></p>
<p>可以看到有四个状态要存储在世界状态的MPT树中，需要存入的值是键值对的形式。自顶向下，我们首先看到的<code>keccak256</code>生成的根哈希，参考默克尔树的<code>Top Hash</code>，其次看到的是绿色的<code>扩展节点Extension Node</code>，其中<code>共同前缀shared nibble</code>是a7，采用了压缩前缀树的方式进行了合并，接着看到蓝色的<code>分支节点Branch Node</code>，其中有表示十六进制的字符和一个value，最后的value是fullnode的数据部分，最后看到紫色的<code>叶子节点leadfNode</code>用来存储具体的数据，它也对路径进行了压缩。</p>
<p>在智能合约执行以后，有一部分数据是需要持久化，参考<a href="http://qyuan.top/2019/09/12/evm/">「EVM深度分析之数据存储(一)」</a>中的<code>Storage</code>中的类型，而一条链上有非常多的合约，每个合约又有很多的数据需要持久化，这个时候就需要用到<code>MPT</code>树。</p>
<blockquote>
<p>在「EVM深度分析之数据存储」中可以看到需要持久化的数据都是以键值对的形式存在的，而键是由keccak256这个函数计算得到，用十六进制表示后刚好对应 MPT 树中分支节点的0-f的16个分支。</p>
</blockquote>
<p>为了避免不同合约有相同的字段，合约又通过地址来进行管理，具体参考<a href="http://qyuan.top/2019/10/08/statedb/">「以太坊账户组织形式」</a>，本质上也是采用MPT树管理合约，合约又采用MPT树管理自身状态。</p>
<p>最终的数据还是以键值对的形式存储在LevelDB中的，MPT树相当于提供了一个缓存，帮助我们快速找到需要的数据，至于最终落盘的数据后面在讲~</p>
]]></content>
    
    <summary type="html">
    
      以太坊Merkle Patricia Tree（MPT）树的数据结构。
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="存储" scheme="qyuan.top/tags/%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>以太坊账户组织形式</title>
    <link href="qyuan.top/2019/10/08/statedb/"/>
    <id>qyuan.top/2019/10/08/statedb/</id>
    <published>2019-10-08T13:01:00.000Z</published>
    <updated>2019-10-08T11:59:28.960Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在以太坊里，账户的状态数据最终是以键值对的形式存储在<code>LevelDB</code>，所有的交易或者操作的结果，作为账户的<code>状态（state）</code>存在，账户是以<code>stateObject</code>体现，而所有的<code>stateObject</code>都接授<code>stateDB</code>的管理。<br><a id="more"></a></p>
<p>&emsp;&emsp;比较直观的表示就是这样：<br><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/statedb/1.jpg?raw=true" width="70%" height="70%"><br>&emsp;&emsp;我们按照<code>StateObject</code>，<code>Address</code>，<code>StateDB</code>自底向上的顺序来看一下各部分的细节。</p>
<h4 id="StateObject"><a href="#StateObject" class="headerlink" title="StateObject"></a>StateObject</h4><p>&emsp;&emsp;一个以太坊账户对应的就是一个<code>StateObject</code>，其中包含着很多非常有用的字段。<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">type</span> stateObject <span class="keyword">struct</span> &#123;</div><div class="line">	address       common.Address</div><div class="line">	addrHash      common.Hash </div><div class="line">	data          Account</div><div class="line">	db            *StateDB</div><div class="line">	dbErr         error</div><div class="line">	trie          Trie</div><div class="line">	code          Code </div><div class="line">	cachedStorage Storage </div><div class="line">	dirtyStorage  Storage </div><div class="line">	dirtyCode     <span class="keyword">bool</span> </div><div class="line">	suicided      <span class="keyword">bool</span></div><div class="line">	touched       <span class="keyword">bool</span></div><div class="line">	deleted       <span class="keyword">bool</span></div><div class="line">	onDirty       <span class="function"><span class="keyword">func</span><span class="params">(addr common.Address)</span> </span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp; 其中比较重要的字段有<code>address</code>,<code>data</code>,<code>code</code>,<code>trie</code>。</p>
<ul>
<li><code>address</code>:  记录了合约的地址;</li>
<li><code>data</code>:  保存了合约的余额，默克尔树根等一些元信息;</li>
<li><code>code</code>:  以<code>[]byte</code>的形式保存了合约的内容;</li>
<li><code>trie</code>:  是<code>StateObject</code>最为核心的字段，通过<code>MPT</code>树来管理合约的数据；</li>
</ul>
<p>&emsp;&emsp;在以太坊中有大量的账户，要找到这些账户就需要<code>address</code>，<code>stateDB</code>也是通过<code>address</code>来管理这些账户的。</p>
<h4 id="StateDB"><a href="#StateDB" class="headerlink" title="StateDB"></a><code>StateDB</code></h4><p>&emsp;&emsp;<code>StateDB</code>用来管理数量众多的账户。<br>&emsp;&emsp;其结构如下：</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">type</span> StateDB <span class="keyword">struct</span> &#123;</div><div class="line">	db   Database</div><div class="line">	trie Trie</div><div class="line">	<span class="comment">// 用于暂存活跃的账户</span></div><div class="line">	stateObjects      <span class="keyword">map</span>[common.Address]*stateObject</div><div class="line">	stateObjectsDirty <span class="keyword">map</span>[common.Address]<span class="keyword">struct</span>&#123;&#125;</div><div class="line">	dbErr error</div><div class="line">	refund <span class="keyword">uint64</span></div><div class="line">	thash, bhash common.Hash</div><div class="line">	txIndex      <span class="keyword">int</span></div><div class="line">	logs         <span class="keyword">map</span>[common.Hash][]*types.Log</div><div class="line">	logSize      <span class="keyword">uint</span></div><div class="line">	preimages <span class="keyword">map</span>[common.Hash][]<span class="keyword">byte</span></div><div class="line">	<span class="comment">// 用于快照，回滚</span></div><div class="line">	journal        journal</div><div class="line">	validRevisions []revision</div><div class="line">	nextRevisionId <span class="keyword">int</span></div><div class="line">	lock sync.Mutex</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;乍一看的反应是账户数据以一个map的形式存在<code>stateObjects</code>字段里，但事实是账户的数据是存储在<code>trie</code>中的，存储的形式和单个合约里状态的状态是一样的。<br>&emsp;&emsp;<code>stateObjects</code>只是作为一个缓存，当创建，获得<code>stateObject</code>的时候会添加进去，提升读取的性能。<br>&emsp;&emsp;我们知道这些账户数据最终是存储在<code>LevelDB</code>中的，<code>stateObjects</code>相当于一级缓存，如果查询不到，可以到<code>trie</code>中查询，如果都查询不到就只能去查找数据库了。<br>&emsp;&emsp;<code>StateDB</code>也支持快照和回滚操作，实现的比较简单，具体的数据在<code>jornal</code>中，而快照的索引，需要回滚的时候只需求拿到索引暂存的数据反序列化回来就可以了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在以太坊里，账户的状态数据最终是以键值对的形式存储在&lt;code&gt;LevelDB&lt;/code&gt;，所有的交易或者操作的结果，作为账户的&lt;code&gt;状态（state）&lt;/code&gt;存在，账户是以&lt;code&gt;stateObject&lt;/code&gt;体现，而所有的&lt;code&gt;stateObject&lt;/code&gt;都接授&lt;code&gt;stateDB&lt;/code&gt;的管理。&lt;br&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>EVM深度分析之数据存储(二)</title>
    <link href="qyuan.top/2019/09/24/evm-2/"/>
    <id>qyuan.top/2019/09/24/evm-2/</id>
    <published>2019-09-24T12:50:28.000Z</published>
    <updated>2019-10-20T12:59:17.939Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;<a href="http://qyuan.top/2019/09/12/evm/">EVM深度分析之数据存储（一）</a>介绍了EVM中不同的数据存储位置的特点，但是并没有对应到具体的存储位置，这篇文章对Storage中的数据是如何被EVM存储做了简要的分析。</p>
<a id="more"></a>
<h3 id="状态变量"><a href="#状态变量" class="headerlink" title="状态变量"></a>状态变量</h3><p>&emsp;&emsp;Storage初始化的时候是空白的，默认是0。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    uint256 a;</div><div class="line">    uint256 b;</div><div class="line">    uint256 c;</div><div class="line">    uint256 d;</div><div class="line">    uint256 e;</div><div class="line">    uint256 f;</div><div class="line">    function test() public &#123;</div><div class="line">      f = 0xc0fefe;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;用<code>solc --bin --asm --optimize test.sol</code>编译合约，可以看到；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tag_5:</div><div class="line">    /* &quot;test.sol&quot;:167:175 0xc0fefe */</div><div class="line">  0xc0fefe</div><div class="line">    /* &quot;test.sol&quot;:163:164 f */</div><div class="line">  0x5</div><div class="line">    /* &quot;test.sol&quot;:163:175 f = 0xc0fefe */</div><div class="line">  sstore</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;这段汇编执行的是<code>sstore(0x5, 0xc0fefe)</code>，把0xc0fefe存储到0x5这个位置，在EVM中声明变量不需要成本，EVM会在编译的时候保留位置，但是不会初始化。</p>
<blockquote>
<p>当通过指令<code>sload</code>读取一个未初始化的变量的时候， 不会报错，只会读取到零值0x0。</p>
</blockquote>
<h3 id="结构体"><a href="#结构体" class="headerlink" title="结构体"></a>结构体</h3><p>&emsp;&emsp;结构体的初始化和变量是一样的；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    struct Tuple &#123;</div><div class="line">      uint256 a;</div><div class="line">      uint256 b;</div><div class="line">      uint256 c;</div><div class="line">      uint256 d;</div><div class="line">      uint256 e;</div><div class="line">      uint256 f;</div><div class="line">    &#125;</div><div class="line">    Tuple t;</div><div class="line">    function test() public &#123;</div><div class="line">      t.f = 0xC0FEFE;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;编译得到；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tag_5:</div><div class="line">    /* &quot;test.sol&quot;:219:227 0xC0FEFE */</div><div class="line">  0xc0fefe</div><div class="line">    /* &quot;test.sol&quot;:213:216 t.f */</div><div class="line">  0x5</div><div class="line">    /* &quot;test.sol&quot;:213:227 t.f = 0xC0FEFE */</div><div class="line">  sstore</div><div class="line">    /* &quot;test.sol&quot;:182:234 function test() public &#123;... */</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;分析编译后的汇编发现结果和状态变量的行为是一致的。</p>
<h3 id="定长数组"><a href="#定长数组" class="headerlink" title="定长数组"></a>定长数组</h3><p>&emsp;&emsp;定长数组EVM很容易知道类型和长度，所以可以依次排列，就像存储状态变量一样。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    uint256[6] numbers;</div><div class="line">    function test() public &#123;</div><div class="line">      numbers[5] = 0xC0FEFE;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;编译合约，可以看到一样的汇编。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">tag_5:</div><div class="line">    /* &quot;test.sol&quot;:110:118 0xC0FEFE */</div><div class="line">  0xc0fefe</div><div class="line">    /* &quot;test.sol&quot;:105:106 5 */</div><div class="line">  0x5</div><div class="line">    /* &quot;test.sol&quot;:97:118 numbers[5] = 0xC0FEFE */</div><div class="line">  sstore</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;但是使用定长数组就会有越界的问题，EVM会在赋值的时候生成汇编检查，具体的内容在下篇合约分析中讨论。</p>
<p>&emsp;&emsp;固定大小的变量都是尽可能打包成32字节的块然后依次存储的，而一些类型是可以动态扩容的，这个时候就需要更加灵活的存储方式了，这些类型有映射（map），数组（array），字节数组（Byte arrays），字符串(string)。</p>
<h3 id="映射（map）"><a href="#映射（map）" class="headerlink" title="映射（map）"></a>映射（map）</h3><p>&emsp;&emsp;通过一个简单的合约学习map的存储方式；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line"></div><div class="line">contract Test &#123;</div><div class="line">  mapping(uint256 =&gt; uint256) items;</div><div class="line"></div><div class="line">  function test() public &#123;</div><div class="line">      items[0x01] = 0x42;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;这个合约很简单，就是创建了一个key和value都是uint256类型的map，并且在用0x01作为key存储了0x42，用<code>solc --bin --asm --optimize test.sol</code>编译合约，得到如下汇编。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">tag_5:</div><div class="line">       /* &quot;test.sol&quot;:119:123 0x01 */</div><div class="line">     0x1</div><div class="line">       /* &quot;test.sol&quot;:113:118 items */</div><div class="line">     0x0</div><div class="line">       /* &quot;test.sol&quot;:113:124 items[0x01] */</div><div class="line">     swap1</div><div class="line">     dup2</div><div class="line">     mstore</div><div class="line">     0x20</div><div class="line">     mstore</div><div class="line">       /* &quot;test.sol&quot;:127:131 0x42 */</div><div class="line">     0x42</div><div class="line">       /* &quot;test.sol&quot;:113:124 items[0x01] */</div><div class="line">     0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7d</div><div class="line">       /* &quot;test.sol&quot;:113:131 items[0x01] = 0x42 */</div><div class="line">     sstore</div><div class="line">       /* &quot;test.sol&quot;:82:136 function test() public &#123;... */</div><div class="line">     jump // out</div></pre></td></tr></table></figure>
<p>&emsp;&emsp;分析一些这段汇编就会发现0x42并不是存储在key是0x01的位置，取而代之的是<code>0xada5013122d395ba3c54772283fb069b10426056ef8ca54750cb9bb552a59e7d</code>这样一段地址，这段地址是通过<code>keccak256( bytes32(0x01) + bytes32(0x00) )</code>计算得到的，0x01就是key，而0x00表示这个合约存储的第一个storage类型变量。<br>&emsp;&emsp;所以key的计算公式就是<code>keccak256(bytes32(key) + bytes32(position))</code></p>
<h5 id="多个映射map"><a href="#多个映射map" class="headerlink" title="多个映射map"></a>多个映射map</h5><p>&emsp;&emsp;假设我们的合约有两个map<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line"></div><div class="line">contract Test &#123;</div><div class="line">  mapping(uint256 =&gt; uint256) itemsA;</div><div class="line">  mapping(uint256 =&gt; uint256) itemsB;</div><div class="line"></div><div class="line">  function test() public &#123;</div><div class="line">    itemsA[0xAAAA] = 0xAAAA;</div><div class="line">    itemsB[0xBBBB] = 0xBBBB;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;编译得到<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">tag_5:</div><div class="line">        /* &quot;test.sol&quot;:166:172 0xAAAA */</div><div class="line">      0xaaaa</div><div class="line">        /* &quot;test.sol&quot;:149:163 itemsA[0xAAAA] */</div><div class="line">      0x839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3</div><div class="line">        /* &quot;test.sol&quot;:149:172 itemsA[0xAAAA] = 0xAAAA */</div><div class="line">      sstore</div><div class="line">        /* &quot;test.sol&quot;:195:201 0xBBBB */</div><div class="line">      0xbbbb</div><div class="line">        /* &quot;test.sol&quot;:149:155 itemsA */</div><div class="line">      0x0</div><div class="line">        /* &quot;test.sol&quot;:178:192 itemsB[0xBBBB] */</div><div class="line">      dup2</div><div class="line">      swap1</div><div class="line">      mstore</div><div class="line">        /* &quot;test.sol&quot;:178:184 itemsB */</div><div class="line">      0x1</div><div class="line">        /* &quot;test.sol&quot;:149:163 itemsA[0xAAAA] */</div><div class="line">      0x20</div><div class="line">        /* &quot;test.sol&quot;:178:192 itemsB[0xBBBB] */</div><div class="line">      mstore</div><div class="line">      0x34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395</div><div class="line">        /* &quot;test.sol&quot;:178:201 itemsB[0xBBBB] = 0xBBBB */</div><div class="line">      sstore</div><div class="line">        /* &quot;test.sol&quot;:120:206 function test() public &#123;... */</div><div class="line">      jump // out</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;itemsA的位置是0，key是0xAAAA:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># key = 0xAAAA, position = 0</div><div class="line">keccak256(bytes32(0xAAAA) + bytes32(0))</div><div class="line">&apos;839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3&apos;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;itemsB的位置是1，key是0xBBBB:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># key = 0xBBBB, position = 1</div><div class="line">keccak256(bytes32(0xBBBB) + bytes32(1))</div><div class="line">&apos;34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395&apos;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;用<code>solc --bin --asm --optimize test.sol</code>编译合约，得到如下汇编。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">/* &quot;test.sol&quot;:166:172 0xAAAA */</div><div class="line">  0xaaaa</div><div class="line">    /* &quot;test.sol&quot;:149:163 itemsA[0xAAAA] */</div><div class="line">  0x839613f731613c3a2f728362760f939c8004b5d9066154aab51d6dadf74733f3</div><div class="line">    /* &quot;test.sol&quot;:149:172 itemsA[0xAAAA] = 0xAAAA */</div><div class="line">  sstore</div><div class="line">    /* &quot;test.sol&quot;:195:201 0xBBBB */</div><div class="line">  0xbbbb</div><div class="line">    /* &quot;test.sol&quot;:149:155 itemsA */</div><div class="line">  0x0</div><div class="line">    /* &quot;test.sol&quot;:178:192 itemsB[0xBBBB] */</div><div class="line">  dup2</div><div class="line">  swap1</div><div class="line">  mstore</div><div class="line">    /* &quot;test.sol&quot;:178:184 itemsB */</div><div class="line">  0x1</div><div class="line">    /* &quot;test.sol&quot;:149:163 itemsA[0xAAAA] */</div><div class="line">  0x20</div><div class="line">    /* &quot;test.sol&quot;:178:192 itemsB[0xBBBB] */</div><div class="line">  mstore</div><div class="line">  0x34cb23340a4263c995af18b23d9f53b67ff379ccaa3a91b75007b010c489d395</div><div class="line">    /* &quot;test.sol&quot;:178:201 itemsB[0xBBBB] = 0xBBBB */</div><div class="line">  sstore</div><div class="line">    /* &quot;test.sol&quot;:120:206 function test() public &#123;... */</div><div class="line">  jump // out</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;可以看到，存储的地址和我们推到的一样。</p>
<h3 id="动态数组"><a href="#动态数组" class="headerlink" title="动态数组"></a>动态数组</h3><p>&emsp;&emsp;在其他语言中，数组只是连续存储在内存中的一系列相同类型的元素，取值的时候都是采用首地址+偏移量的形式，但是在solidity中，数组是一种映射。数组在存储器中是这样存储的；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">0x290d...e563</div><div class="line">0x290d...e564</div><div class="line">0x290d...e565</div><div class="line">0x290d...e566</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;虽然看起来像是连续存储的，但实际上访问的时候是通过映射来查找的。增加了数组类型的意义在于多了一些数组的方法，便于我们更好的理解和编写代码，增加的特性有；</p>
<ul>
<li>length表示数组的长度，一共有多少元素；</li>
<li>边界检查，当读取或者写入时索引值大于length就会报错；</li>
<li>比映射更加复杂的存储打包行为；</li>
<li>当数组变小时，自动清除未使用的空间；</li>
<li>bytes和string的特殊优化让短数组（小于32字节）存储更加高效；</li>
</ul>
<p>&emsp;&emsp;编译合约<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    uint256[] chunks;</div><div class="line">    function test() public &#123;</div><div class="line">      chunks.push(0xAA);</div><div class="line">      chunks.push(0xBB);</div><div class="line">      chunks.push(0xCC);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;使用<code>remix</code>调试合约可以看到storage部分的存储内容；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/evm2/1.jpg?raw=true" width="85%" height="50%"></p>
<p>&emsp;&emsp;因为动态数组在编译期间无法知道数组的长度，提前预留存储空间，所以solidity就用<code>chunks</code>变量的位置存储了动态数组的长度，而具体的数据地址通过计算<code>keccak256(bytes32(0))</code>算得数组首地址，再加数组长度偏移量获得具体的元素。</p>
<blockquote>
<p>这里的 0 表示的是chunks变量的位置哦</p>
</blockquote>
<h3 id="动态数据打包"><a href="#动态数据打包" class="headerlink" title="动态数据打包"></a>动态数据打包</h3><p>&emsp;&emsp;数组与映射相比，有更加优化的打包行为，编译合约；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    uint128[] s;</div><div class="line">    function test() public &#123;</div><div class="line">        s.length = 4;</div><div class="line">        s[0] = 0xAA;</div><div class="line">        s[1] = 0xBB;</div><div class="line">        s[2] = 0xCC;</div><div class="line">        s[3] = 0xDD;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;使用<code>remix</code>调试合约可以看到storage部分的存储内容；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/evm2/2.jpg?raw=true" width="85%" height="50%"></p>
<p>&emsp;&emsp;可以发现4个元素并没有占据4个插槽，而只有两个，solidity一个插糟的大小是256bit，s的类型是uint128，编译器做了一个优化，对数据进行了更优化的打包策略，可以最大限度的节约Gas。</p>
<p>&emsp;&emsp;看一些各项操作所花费Gas的表格；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/evm2/3.png?raw=true" width="85%" height="50%"></p>
<p>&emsp;&emsp;其中数据的持久化操作<code>sstore</code>是消耗Gas最多的操作，在合适的场景下使用数组可以利用编译器优化节约大量的Gas。</p>
<h3 id="字节数组和字符串"><a href="#字节数组和字符串" class="headerlink" title="字节数组和字符串"></a>字节数组和字符串</h3><p>&emsp;&emsp;bytes和string是EVM特殊优化的类型；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line">contract C &#123;</div><div class="line">    bytes s;</div><div class="line">    function test() public &#123;</div><div class="line">        s.push(0xAA);</div><div class="line">        s.push(0xBB);</div><div class="line">        s.push(0xCC);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;最后用remix编译得到;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">key: 0x0000000000000000000000000000000000000000000000000000000000000000</div><div class="line">value: 0xaabbcc0000000000000000000000000000000000000000000000000000000006</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;当bytes和string的长度小于31字节的时候可以这样放到一个插槽里，但是当大于31字节的时候，就采用存储动态数组的方式。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>&emsp;&emsp;EVM的存储器就是一个健值数据库，当改变里面的任何一点东西，根节点的校验和也会改变，如果两个根节点拥有相同的校验和，存储的数据就能保持一致。</p>
]]></content>
    
    <summary type="html">
    
      EVM以太坊虚拟机
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>EVM深度分析之数据存储(一)</title>
    <link href="qyuan.top/2019/09/12/evm/"/>
    <id>qyuan.top/2019/09/12/evm/</id>
    <published>2019-09-12T10:11:45.000Z</published>
    <updated>2019-09-24T11:50:17.403Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;以太坊虚拟机<code>EVM</code>的作用是将智能合约代码翻译成可以在以太坊上执行的机器码，并且提供一个沙盒运行环境，在运行期间不能访问宿主机的网络，文件，系统，即使不同的合约之间也有有限的访问权限。</p>
<a id="more"></a>
<h3 id="EVM的特点"><a href="#EVM的特点" class="headerlink" title="EVM的特点"></a>EVM的特点</h3><p>&emsp;&emsp;官方给出的EVM主要的设计目标如下：</p>
<ul>
<li>简单性，操作码尽可能少且低级，数据类型尽可能少，虚拟机的结构尽可能简单。</li>
<li>确定性，EVM的语句没有产生歧义的空间，结果在不同机器上的执行结果是确定一致的。</li>
<li>节约空间，EVM的组件尽可能紧凑。</li>
<li>区块链定制化的，必须可以处理20bytes的账户地址，自定义32bytes密码学算法的等。</li>
<li>安全模型简单安全，Gas的计价模型应该是简单易行准确的。</li>
<li>便于优化，以便即时编译（JIT）和VM的性能优化。</li>
</ul>
<h3 id="EVM基本信息"><a href="#EVM基本信息" class="headerlink" title="EVM基本信息"></a>EVM基本信息</h3><p>&emsp;&emsp;以太坊是一种基于栈的虚拟机，基于栈的虚拟机数据的存取为先进先出，在后面介绍EVM指令的时候会看到这个特性。同时基于栈的虚拟机实现简单，移植性也不错，这也是以太坊选择基于栈的虚拟机的原因。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/evm/2.jpg?raw=true" width="70%" height="50%"></p>
<p>&emsp;&emsp;EVM采用了32字节（256bit）的<code>字长</code>，最多可以容纳2014个<code>字</code>，<code>字</code>为最小的操作单位。</p>
<h3 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h3><p>&emsp;&emsp;接下来看一下EVM的数据是如何管理的。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/evm/1.jpg?raw=true" width="70%" height="70%"></p>
<p>&emsp;&emsp;可以看到code和storage里存储的数据是非易失的，而stack，args，memory里存储的数据是易失的，其中code的数据是智能合约的二进制源码，是非易失的很好理解，部署合约的时候data字段也就是合约内容会存储在EVM的code中。<br>&emsp;&emsp;如果要操作这些存储结构里的数据，就需要用到EVM指令，由于EVM的操作码被限制在一个字以内，所以EVM最多容纳256条指令，目前EVM已经定义了约142条指令，还有100多条用于以后的扩展。这142条指令包括了算法运算，密码学计算，栈操作，memory，storage操作等。</p>
<p>&emsp;&emsp;接下来看一下各个存储位置的含义；</p>
<h5 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h5><p>&emsp;&emsp; <code>stack</code>可以免费使用，没有gas消耗，用来保存函数的局部变量，数量被限制在了16个，当在合约里中声明的局部变量超过16个时，再编译合约就会遇到<code>Stack too deep, try removing local variables</code>错误。<br>&emsp;&emsp;介绍几个EVM操作栈的指令，在后面分析合约的时候会用到；</p>
<ul>
<li>Pop指令（操作码0x50）用来从栈顶弹出一个元素；</li>
<li>PushX指令用来把紧跟在后面的1-32字节元素推入栈顶，Push指令一共32条，从Push1（0x60）到Push32（0x7A），因为栈的一个<code>字</code>是256bit，一个字节8bit，所以Push指令最多可以把其后32字节的元素放入栈中而不溢出。</li>
<li>DupX指令用来复制从栈顶开始的第1-16个元素，复制后把元素在推入栈顶，Dup指令一共16条，从Dup1（0x80）到Dup16（0x8A）。</li>
<li>SwapX指令把栈顶元素和从栈顶开始数的第1-16个元素进行交换，Swap指令一共16条，从Swap1（0x01）一直到Swap16（0x9A）。</li>
</ul>
<h5 id="Args"><a href="#Args" class="headerlink" title="Args"></a>Args</h5><p>&emsp;&emsp;<code>args</code>也叫<code>calldata</code>，是一段只读的可寻址的保存函数调用参数的空间，与栈不同的地方的是，如果要使用calldata里面的数据，必须手动指定偏移量和读取的字节数。<br>&emsp;&emsp;EVM提供的用于操作calldata的指令有三个：</p>
<ul>
<li><code>calldatasize</code>返回calldata的大小。</li>
<li><code>calldataload</code>从calldata中加载32bytes到stack中。</li>
<li><code>calldatacopy</code>拷贝一些字节到内存中。</li>
</ul>
<p>&emsp;&emsp;通过一个合约来看一下如何使用<code>calldata</code>，假如我们要写一个合约，合约有一个add的方法，用来把传入的两个参数相加，通常会这样写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">pragma solidity ^0.5.1;</div><div class="line"></div><div class="line">contract Calldata &#123;</div><div class="line">  function add(uint256 a, uint256 b) public view returns (uint256) &#123;</div><div class="line">      return a + b;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;当然我们也可以用内联汇编的形式这样写。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">contract Calldata &#123;</div><div class="line">  function add(uint256 a, uint256 b) public view returns (uint256) &#123;</div><div class="line">    assembly &#123;</div><div class="line">      let a := mload(0x40)</div><div class="line">      let b := add(a, 32)</div><div class="line">      calldatacopy(a, 4, 32)</div><div class="line">      calldatacopy(b, add(4, 32), 32)</div><div class="line">      result := add(mload(a), mload(b))</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;首先我们我们加载了0x40这个地址，这个地址EVM存储空闲memory的指针，然后我们用a重命名了这个地址，接着我们用b重命名了a偏移32字节以后的空余地址，到目前为止这个地址所指向的内容还是空的。<br>&emsp;&emsp;<code>calldatacopy(a, 4, 32)</code>这行代码把calldata的从第4字节到第36字节的数据拷贝到了a中，同样<code>calldatacopy(b, add(4, 32), 32)</code>把36到68字节的数据拷贝到了b中，接着<code>add(mload(a), mload(b))</code>把栈中的a，b加载到内存中相加。最后的结果等价于第一个合约。<br>&emsp;&emsp;而为什么<code>calldatacopy(a, 4, 32)</code>的偏移要从4开始呢？在EVM中，前四位是存储函数指纹的，计算公式是bytes4(keccak256(“add(uint256, uint256)”))，从第四位开始才是args。</p>
<h5 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h5><p>&emsp;&emsp;Memory是一个易失性的可以读写修改的空间，主要是在运行期间存储数据，将参数传递给内部函数。内存可以在字节级别寻址，一次可以读取32字节。<br>&emsp;&emsp;EVM提供的用于操作memory的指令有三个：</p>
<ul>
<li>Mload加载一个字从stack到内存；</li>
<li>Mstore存储一个值到指定的内存地址，格式mstore（p，v），存储v到地址p；</li>
<li>Mstore8存储一个byte到指定地址 ；</li>
</ul>
<p>&emsp;&emsp;当我们操作内存的时候，总是需要加载0x40，因为这个地址保存了空闲内存的指针，避免了覆盖已有的数据。</p>
<h5 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h5><p>&emsp;&emsp;Storage是一个可以读写修改的持久存储的空间，也是每个合约持久化存储数据的地方。Storage是一个巨大的map，一共2^256个插槽，一个插糟有32byte。<br>&emsp;&emsp;EVM提供的用于操作storage的指令有两个：</p>
<ul>
<li>Sload用于加载一个字到stack中；</li>
<li>Sstore用于存储一个字到storage中；</li>
</ul>
<p>&emsp;&emsp;solidity将定义的状态变量，映射到插糟内，对于静态大小的变量从0开始连续布局，对于动态数组和map则采用了其他方法，下篇文章在讲 (<em>╹▽╹</em>)</p>
]]></content>
    
    <summary type="html">
    
      EVM以太坊虚拟机
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="以太坊" scheme="qyuan.top/tags/%E4%BB%A5%E5%A4%AA%E5%9D%8A/"/>
    
  </entry>
  
  <entry>
    <title>详解实用拜占庭协议Pbft（三）</title>
    <link href="qyuan.top/2019/09/03/pbft-3/"/>
    <id>qyuan.top/2019/09/03/pbft-3/</id>
    <published>2019-09-03T11:10:21.000Z</published>
    <updated>2019-09-03T11:34:50.332Z</updated>
    
    <content type="html"><![CDATA[<h3 id="主动恢复"><a href="#主动恢复" class="headerlink" title="主动恢复"></a>主动恢复</h3><p>&emsp;&emsp;集群在运行过程中，可能出现网络抖动、磁盘故障等原因，会导致部分节点的执行速度落后大多数节点，而传统的PBFT拜占庭共识算法并没有实现主动恢复的功能，因此需要添加主动恢复的功能才能参与后续的共识流程，主动恢复会索取网络中其他节点的视图，最新的区块高度等信息，更新自身的状态，最终与网络中其他节点的数据保持一致。<br>&emsp;&emsp;在<code>Raft</code>中采用的方式是主节点记录每个跟随者提交的日志编号，发送心跳包时携带额外信息的方式来保持同步，在<code>Pbft</code>中采用了<code>视图协商（NegotiateView）</code>的机制来保持同步。<br>&emsp;&emsp;一个节点落后太多，这个时候它收到主节点发来的消息时，对消息<code>水线（water mark）</code>的检查会失败，这个时候计时器超时，发送<code>view-change</code>的消息，但是由于只有自己发起<code>view-change</code>达不到<code>2f+1</code>个节点的数量，本来正常运行的节点就退化为一个拜占庭节点，尽管是非主观的原因，为了尽可能保证集群的稳定性，所以加入了<code>视图协商（NegotiateView）</code>机制。<br>&emsp;&emsp;当一个节点多次<code>view-change</code>失败就触发<code>NegotiateView</code>同步集群数据，流程如下；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/pbft3/1.png?raw=true" width="70%" height="70%"></p>
<ul>
<li>新增节点<code>Replica 4</code>发起<code>NegotiateView</code>消息给其他节点；</li>
<li>其余节点收到消息以后，返回自己的视图信息，节点ID，节点总数N；</li>
<li><code>Replica 4</code>收到<code>2f+1</code>个相同的消息后，如果quorum个视图编号和自己不同，则同步view和N；</li>
<li><code>Replica 4</code>同步完视图后，发送<code>RevoeryToCheckpoint</code>的消息，其中包含自身的<code>checkpoint</code>信息；</li>
<li>其余节点收到<code>RevoeryToCheckpoint</code>后将自身最新的检查点信息返回给<code>Replica 4</code>;</li>
<li><code>Replica 4</code>收到quorum个消息后，更新自己的检查点到最新，更新完成以后向正常节点索要pset、qset和cset的信息（即PBFT算法中pre-prepare阶段、prepare阶段和commit阶段的数据）同步至全网最新状态；</li>
</ul>
<h3 id="增删节点"><a href="#增删节点" class="headerlink" title="增删节点"></a>增删节点</h3><p>&emsp;&emsp;<code>Replica 5</code>新节点加入的流程如下图所示；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/pbft3/2.jpg?raw=true" width="70%" height="70%"></p>
<ul>
<li>新节点启动以后，向网络中其他节点建立连接并且发送<code>AddNode</code>消息；</li>
<li>当集群中的节点收到<code>AddNode</code>消息后，会广播<code>AgreeAdd</code>的消息；</li>
<li>当一个节点收到<code>2f+1</code>个<code>AgreeAdd</code>的消息后，会发送<code>AgreeAdd</code>的消息给<code>Replica 5</code></li>
<li><code>Replica 5</code>会从收到的消息中，挑选一个节点同步数据，具体的过程在主动恢复中有说明，同步完成以后发送<code>JoinNet</code></li>
<li>当集群中其他节点收到<code>JoinNet</code>之后重新计算视图view，节点总数N，同时将PQC信息封装到<code>AgreeJoinOrExit</code>中广播</li>
<li>当收到<code>2f+1</code>个有效的<code>AgreeJoinOrExit</code>后，新的主节点广播<code>UpdateNet</code>消息完成新增节点流程</li>
</ul>
<p>&emsp;&emsp;删除节点的流程和新增节点的过程类似：</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/pbft3/3.jpg?raw=true" width="70%" height="70%"></p>
<h3 id="QA"><a href="#QA" class="headerlink" title="QA"></a>QA</h3><p>Q：为什么<code>PBFT</code>算法需要三个阶段？<br>A：假如简化为两个阶段<code>pre-prepare</code>和<code>prepare</code>，当一个节点A收到<code>2f+1</code>个相同的<code>prepare</code>后执行请求，一部分节点B发生<code>view-change</code>，在<code>view-change</code>的过程中是拒收<code>prepare</code>消息的，所以这一部分节点的状态机会少执行一个请求，当<code>view-change</code>切换成功后重放<code>prepare</code>消息，在重放的过程中，节点A也完成了<code>view-change</code>，这个时候A就会面临重放的<code>prepare</code>已经执行过了，是否需要再次执行？会导致状态机出现二义性。</p>
<hr>
<p>Q：view-change阶段集群会不可用么？<br>A：view-change阶段集群会出现短暂的不可用，一般在实践的时候都会实现一个缓冲区来减少影响，实现参考 <a href="http://qyuan.top/2019/06/02/txpool/">以太坊TXpool分析</a>。</p>
<hr>
<p>Q：Pbft算法的时间复杂度？<br>A：Pbft算法的时间复杂度O(n^2)，在<code>prepare</code>和<code>commit</code>阶段会将消息广播两次，一般而言，Pbft集群中的节点都不会超过100。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;主动恢复&quot;&gt;&lt;a href=&quot;#主动恢复&quot; class=&quot;headerlink&quot; title=&quot;主动恢复&quot;&gt;&lt;/a&gt;主动恢复&lt;/h3&gt;&lt;p&gt;&amp;emsp;&amp;emsp;集群在运行过程中，可能出现网络抖动、磁盘故障等原因，会导致部分节点的执行速度落后大多数节点，而传统的
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>详解实用拜占庭协议Pbft（二）</title>
    <link href="qyuan.top/2019/08/25/pbft-2/"/>
    <id>qyuan.top/2019/08/25/pbft-2/</id>
    <published>2019-08-25T11:12:59.000Z</published>
    <updated>2019-08-25T11:16:41.512Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;<a href="http://qyuan.top/2019/08/13/pbft-1/">「详解实用拜占庭协议Pbft（一)」</a>中介绍了<code>Pbft</code>算法的正常流程，但是还有一些可用性方面的问题没有解决，比如日志无限增长，主节点故障，增删节点。</p>
<a id="more"></a>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>&emsp;&emsp;<code>Pbft</code>算法在运行的过程中，日志会不断累积的，但是在实际的系统中，无论是从日志占用的磁盘空间，还是新节点加入集群，同步日志的网络消耗来看，日志都不能无限的增长。</p>
<p>&emsp;&emsp;<code>Pbft</code>采用<code>检查点（checkpoint）</code>机制来压缩日志，其本质和<code>Raft</code>算法采用快照的形式清理日志是一样的，只是实现的方式不同。</p>
<p>&emsp;&emsp;为每一次操作创建一个集群中稳定检查点，代价是非常昂贵的，<code>Pbft</code>为常数个操作创建一次稳定检查点，比如每100个操作创建一次检查点，而这个检查点就是<code>checkpoint</code>，当这个<code>checkpoint</code>得到集群中多数节点认可以后，就变成了稳定检查点<code>stable checkpoint</code>。</p>
<p>&emsp;&emsp;当节点<code>i</code>生成<code>checkpoint</code>后会广播消息<code>&lt;CHECKPOINT, n, d, i&gt;</code>其中<code>n</code>是最后一次执行的消息序号，<code>d</code>是<code>n</code>执行后的状态机状态的摘要。每个节点收到<code>2f+1</code>个相同<code>n</code>和<code>d</code>的<code>checkpoint</code>消息以后，<code>checkpoint</code>就变成了<code>stable checkpoint</code>。同时删除本地序号小于等于<code>n</code>的消息。</p>
<p>&emsp;&emsp;同时<code>checkpoint</code>还有一个提高<code>水线（water mark）</code>的作用，当一个<code>stable checkpoint</code>被创建的时候，水线<code>h</code>被修改为<code>stable checkpoint</code>的<code>n</code>，水线<code>H</code>为<code>h + k</code>而<code>k</code>就是之前用到创建<code>checkpoint</code>的那个常数。</p>
<h3 id="视图切换（View-Change）"><a href="#视图切换（View-Change）" class="headerlink" title="视图切换（View-Change）"></a>视图切换（View-Change）</h3><p>&emsp;&emsp;在正常流程中，可以看到所有客户端发来的消息<code>m</code>都是由主节点<code>p</code>广播到集群的，但是当主节点突然宕机，又怎么保证集群的可用性呢？</p>
<p>&emsp;&emsp;<code>view-change</code>提供了一种当主节点宕机以后依然可以保证集群可用性的机制。<code>view-change</code>通过计时器来进行切换，避免副本长时间的等待请求。<br>&emsp;&emsp;当副本收到请求时，就启动一个计时器，如果这个时候刚好有定时器在运行就重置（reset）定时器，但是<code>主节点</code>宕机的时候，副本<code>i</code>就会在当前<code>视图</code>v中超时，这个时候副本<code>i</code>就会触发<code>view-change</code>的操作，将视图切换为<code>v+1</code>。</p>
<ul>
<li>副本<code>i</code>会停止接收除了<code>checkpoint</code>，<code>view-change</code>和<code>new view-change</code>以外的请求，同时广播消息<code>&lt;VIEW-CHANGE, v+1, n, C, P, i&gt;</code>的消息到集群。<ol>
<li><code>n</code>是节点<code>i</code>知道的最后一个<code>stable checkpoint</code>的消息序号。</li>
<li><code>C</code>是节点<code>i</code>保存的经过<code>2f+1</code>个节点确认<code>stable checkpoint</code>消息的集合。</li>
<li><code>P</code>是一个保存了<code>n</code>之后所有已经达到<code>prepared</code>状态消息的集合。</li>
</ol>
</li>
<li>当在视图( v+1 )中的主节点<code>p1</code>接收到<code>2f</code>个有效的将视图变更为<code>v+1</code>的消息以后，<code>p1</code>就会广播一条消息<code>&lt;NEW-VIEW, v+1, V, Q&gt;</code><ol>
<li><code>V</code>是<code>p1</code>收到的，包括自己发送的<code>view-change</code>的消息集合。</li>
<li><code>Q</code>是<code>PRE-PREPARE</code>状态的消息集合，但是这个<code>PRE-PREPARE</code>消息是从<code>PREPARE</code>状态的消息转换过来的。</li>
</ol>
</li>
<li>从节点接收到<code>NEW-VIEW</code>消息后，校验签名，<code>V</code>和<code>Q</code>中的消息是否合法，验证通过，主节点和副本都 进入视图<code>v+1</code>。</li>
</ul>
<p>&emsp;&emsp;当<code>p1</code>在接收到<code>2f+1</code>个<code>VIEW-CHANGE</code>消息以后，可以确定<code>stable checkpoint</code>之前的消息在视图切换的过程中不会丢，但是当前检查点之后，下一个检查点之前的已经<code>PREPARE</code>可能会被丢弃，在视图切换到<code>v+1</code>后，<code>Pbft</code>会把旧视图中已经<code>PREPARE</code>的消息变为<code>PRE-PREPARE</code>然后新广播。</p>
<ul>
<li>如果集合<code>P</code>为空，广播<code>&lt;PRE-PREPARE, v+1, n, null&gt;</code>，接收节点就什么也不做。</li>
<li>如果集合<code>P</code>不为空，广播<code>&lt;PRE-PREPARE, v+1, n,d&gt;</code></li>
</ul>
<p>&emsp;&emsp;总结一下，在<code>view-change</code>中最为重要的就是<code>C</code>，<code>P</code>，<code>Q</code>三个消息的集合，<code>C</code>确保了视图变更的时候，<code>stable checkpoint</code>之前的状态安全。<code>P</code>确保了视图变更前，已经<code>PREPARE</code>的消息的安全。<code>Q</code>确保了视图变更后<code>P</code>集合中的消息安全。回想一下<code>pre-prepare</code>和<code>prepare</code>阶段最重要的任务是保证，同一个<code>主节点</code>发出的请求在同一个<code>视图（view）</code>中的顺序是一致的，而在视图切换过程中的<code>C</code>，<code>P</code>，<code>Q</code>三个集合就是解决这个问题的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;&lt;a href=&quot;http://qyuan.top/2019/08/13/pbft-1/&quot;&gt;「详解实用拜占庭协议Pbft（一)」&lt;/a&gt;中介绍了&lt;code&gt;Pbft&lt;/code&gt;算法的正常流程，但是还有一些可用性方面的问题没有解决，比如日志无限增长，主节点故障，增删节点。&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>详解实用拜占庭协议Pbft（一)</title>
    <link href="qyuan.top/2019/08/13/pbft-1/"/>
    <id>qyuan.top/2019/08/13/pbft-1/</id>
    <published>2019-08-13T13:40:19.000Z</published>
    <updated>2019-08-14T13:01:29.965Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;<code>PBFT</code>算法和<code>Raft</code>算法解决的核心问题都是在分布式环境下如何保持集群状态的一致性，简而言之就是一组服务，给定一组操作，最后得到一致的结果。</p>
<a id="more"></a>
<p>&emsp;&emsp;<code>PBFT</code>算法假设的环境又比<code>Raft</code>算法更加的’恶劣‘，<code>Raft</code>算法只支持容错故障节点，而<code>PBFT</code>算法除了需要支持容错故障节点之外，还需要容忍作恶节点。</p>
<blockquote>
<p>作恶节点节点是指可能对接收到的消息作出截然相反的回复，甚至伪造消息。</p>
</blockquote>
<p>&emsp;&emsp;<code>PBFT</code>算法中节点只有两种角色，<code>主节点（primary）</code>和<code>副本（replica）</code>，两种角色之间可以相互转换。两者之间的转换又引入了<code>视图（view）</code>的概念，<code>视图</code>在<code>PBFT</code>算法中起到逻辑时钟的作用。</p>
<p>&emsp;&emsp;为了更多的容错性，<code>PBFT</code>算法最大的容错节点数量<code>( n - 1 ) / 3</code>，也就是是说4个节点的集群最多只能容忍一个节点作恶或者故障。而<code>Raft</code>算法的最大容错节点是<code>( n - 1) / 2</code>，5个节点的集群可以容忍2个节点故障。</p>
<h3 id="为什么PBFT算法只能容忍（n-1-3个作恶节点？"><a href="#为什么PBFT算法只能容忍（n-1-3个作恶节点？" class="headerlink" title="为什么PBFT算法只能容忍（n-1)/3个作恶节点？"></a>为什么<code>PBFT</code>算法只能容忍<code>（n-1)/3</code>个作恶节点？</h3><p>&emsp;&emsp; 节点总数是<code>n</code>，其中作恶节点有<code>f</code>，那么剩下的正确节点为<code>n - f</code>，意味着只要收到<code>n - f</code>个消息就能做出决定，但是这<code>n - f</code>个消息有可能由<code>f</code>个是由作恶节点冒充的，那么正确的消息就是<code>n - f - f</code>个，为了多数一致，正确消息必须占多数，也就是<code>n - f - f &gt; f</code>但是节点必须是整数个，所以n最少是<code>3f+1</code>个。<br>&emsp;&emsp;或者可以这样理解，假定<code>f</code>个节点是故障节点，<code>f</code>个节点是作恶，那么达成一致需要的正确节点最少就是<code>f+1</code>个，当然这是最坏的情况，如果故障节点集合和拜占庭节点集合有重复，可以不需要<code>f+1</code>个正确节点，但是为了保证最坏的情况算法还能正常运行，所以必须保证正确节点数量是<code>f+1</code>个。</p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>&emsp;&emsp;在算法开始阶段，<code>主节点</code>由 <code>p = v mod n</code>计算得出，随着<code>v</code>的增长可以看到<code>p</code>不断变化，论文里目前还是轮流坐庄的方法，这里是一个优化点。</p>
<p>&emsp;&emsp;首先客户端发送消息<code>m</code>给主节点<code>p</code>，主节点就开始了<code>PBFT</code>三阶段协议，三个阶段分别是<code>预准备（pre-prepare）</code>，<code>准备（prepare）</code>，<code>提交（commit）</code>。<br>&emsp;&emsp;其中<code>pre-prepare</code>和<code>prepare</code>阶段最重要的任务是保证，同一个<code>主节点</code>发出的请求在同一个<code>视图（view）</code>中的顺序是一致的，<code>prepare</code>和<code>commit</code>阶段最重要的任务是保证请求在不同<code>视图</code>之间的顺序是一致的。</p>
<ul>
<li>主节点收到客户端发送来的消息后，构造<code>pre-prepare</code>消息结构体<code>&lt; &lt;PRE-PREPARE, v, n, d&gt;, m &gt;</code>广播到集群中的其它节点。<ol>
<li><code>PRE-PREPARE</code>标识当前消息所处的协议阶段。</li>
<li><code>v</code>标识当前视图编号。</li>
<li><code>n</code>为主节点广播消息的一个唯一递增序号。</li>
<li><code>d</code>为<code>m</code>的消息摘要。</li>
<li><code>m</code>为客户端发来的消息。</li>
</ol>
</li>
<li><p><code>副本(backup)</code>收到主节点请求后，会对消息进行检查，检查通过会存储在本节点。当节点收到<code>2f+1</code>（包括自己）个相同的消息后，会进入<code>PREPARE</code>状态，广播消息<code>&lt; &lt;PREPARA, v, n, d, i&gt; &gt;</code>，其中<code>i</code>是本节点的编号。对消息的有效性有如下检查：</p>
<ol>
<li>检查收到的消息体中摘要<code>d</code>，是否和自己对<code>m</code>生成的摘要一致，确保消息的完整性。</li>
<li>检查<code>v</code>是否和当前视图<code>v</code>一致。</li>
<li>检查序号<code>n</code>是否在水线<code>h</code>和<code>H</code>之间，避免快速消耗可用序号。</li>
<li>检查之前是否接收过相同序号<code>n</code>和<code>v</code>，但是不同摘要<code>d</code>的消息。</li>
</ol>
</li>
<li><p><code>副本</code>收到<code>2f+1</code>（包括自己）个一致的<code>PREPARE</code>消息后，会进入<code>COMMIT</code>阶段，并且广播消息<code>&lt; COMMIT, v, n, D(m), i &gt;</code>给集群中的其它节点。在收到<code>PREPARE</code>消息后，副本同样也会对消息进行有效性检查，检查的内容是上文<code>1, 2, 3</code>。</p>
</li>
<li><p><code>副本</code>收到<code>2f+1</code>（包括自己）个一致的<code>COMMIT</code>个消息后执行<code>m</code>中包含的操作，其中，如果有多个<code>m</code>则按照序号<code>n</code>从小到大执行，执行完毕后发送执行成功的消息给客户端。</p>
</li>
</ul>
<p>下面就是算法的流程图：</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/pbft1/pbft-1.jpeg?raw=true" width="70%" height="70%"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;&lt;code&gt;PBFT&lt;/code&gt;算法和&lt;code&gt;Raft&lt;/code&gt;算法解决的核心问题都是在分布式环境下如何保持集群状态的一致性，简而言之就是一组服务，给定一组操作，最后得到一致的结果。&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性协议之Raft(三)</title>
    <link href="qyuan.top/2019/08/03/raft-2/"/>
    <id>qyuan.top/2019/08/03/raft-2/</id>
    <published>2019-08-03T14:27:56.000Z</published>
    <updated>2019-08-03T15:10:44.569Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在前两篇文章中已经介绍了<code>Raft</code>算法的正常流程和对异常的处理，但是还有一些问题没有解决，比如当集群中有新的节点加入或者退出的时候，集群又该如何保证安全的提供服务呢？</p>
<a id="more"></a>
<h3 id="增删集群节点"><a href="#增删集群节点" class="headerlink" title="增删集群节点"></a>增删集群节点</h3><p>&emsp;&emsp;最容易想到的方法就是暂停整个集群，更新配置，然后重启集群。但是问题显而易见，在更新配置期间集群是不可用的，而手工操作配置文件，而且是操作多个节点的配置文件，也会造成很大的风险。为了避免发生这些风险，<code>Raft</code>算法添加了自动化配置变更的内容。<br>&emsp;&emsp;从旧的配置直接变更到新的配置的各种方法都是不安全的，其中最大的问题就是容易出现<code>脑裂</code>集群分裂，举个例子；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft2/1.png?raw=true" width="70%" height="70%"></p>
<p>&emsp;&emsp;旧配置有 1， 2， 3号节点，<code>候选人</code>只需要两张选票就可以变为<code>领导者</code>，除了自己的一张选票，还需要等待一个节点投票给自己即可，但是当集群增加2个节点的时候，旧节点之间是无法感知有几个节点加入网络的，所以还会按照旧配置投票，即收集到两张选票就可以成为候选人。而新节点是可以感知到集群中是有5个节点的，所以新节点要成为领导者需要3张选票，必然有一个时间点，既可满足旧节点的候选人选举要求，又可满足新节点的选举要求，<code>脑裂</code>就这样发生了。</p>
<p>&emsp;&emsp;显而易见，出现<code>脑裂</code>的问题是由于同一时间新旧配置节点各自单方面的作出了选<code>领导者</code>的决定。</p>
<p>&emsp;&emsp;停集群，更新配置，重启集群其实目的就是保证了同一时间只有一种状态，为了解决集群的可用性，<code>Raft</code>采取了两段提交来保证安全的变更日志。</p>
<h4 id="配置变更流程"><a href="#配置变更流程" class="headerlink" title="配置变更流程"></a>配置变更流程</h4><p>&emsp;&emsp;首先当一个<code>领导者</code>收到一个改变配置从<code>C-old</code>到<code>C-new</code>的请求时，它会<code>merge(C-old, C-new)</code>并且保存到自己的日志中，然后复制到集群中的其他节点，在<code>C-new</code>提交之前，所有节点的决定都会基于<code>C-old,new</code>的配置做决定。<br>&emsp;&emsp;在<code>C-old, new</code>被提交以后，<code>领导者</code>创建一条<code>C-new</code>的配置复制到集群，当<code>C-new</code>被提交以后，就旧配置指定的节点就无关紧要了，在集群中不可见了，可以从集群移除。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft2/2.png?raw=true" width="70%" height="70%"></p>
<h4 id="异常处理流程"><a href="#异常处理流程" class="headerlink" title="异常处理流程"></a>异常处理流程</h4><h5 id="节点宕机"><a href="#节点宕机" class="headerlink" title="节点宕机"></a>节点宕机</h5><p>&emsp;&emsp;但是在这个过程中还是会有节点宕机的异常情况发生，<code>Raft</code>又是如何保证整个增删节点过程的安全性呢？<br>&emsp;&emsp;如果领导者在复制包含配置文件的日志时候崩溃了，跟随者节点只有两种配置状态，<code>C-old,new</code>或者<code>C-old</code>，主要观察<code>C-old,new</code>是否能被复制到了大多数节点。但是无论哪种状态，<code>C-new</code>都不会单方面做出决定。</p>
<h5 id="空白节点加入"><a href="#空白节点加入" class="headerlink" title="空白节点加入"></a>空白节点加入</h5><p>&emsp;&emsp;当一个新的服务器加入集群，新服务器本身是没有存储任何日志，是无法提交集群中的任何一条日志的，需要一段时间来追赶，<code>Raft</code>为了避免这种可用性的时间间隔太长，采取了节点静默加入集群，但是没有投票权，只是同步日志，当新节点已经可以跟上集群日志的时候再投票加入集群。</p>
<h5 id="旧节点干扰"><a href="#旧节点干扰" class="headerlink" title="旧节点干扰"></a>旧节点干扰</h5><p>&emsp;&emsp;当<code>C-new</code>被提交以后，就需要移除不在<code>C-new</code>中的节点。在<code>C-new</code>被提交后，需要移除的节点就接收不到<code>领导者</code>的心跳消息，这个时候这些节点认为<code>领导者</code>可能出现了故障，会发起选举，正常执行的<code>领导者</code>收到投票请求后会退回到<code>跟随者</code>状态等待新<code>领导者</code>被选出，虽然最终正确的<code>领导者</code>会被选出，但是频繁的选举流程会扰乱集群的可用性。<br>&emsp;&emsp;为了避免这个问题，<code>Raft</code>采用了<code>最小选举超时时间</code>的机制，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票，这样就避免了频繁的状态切换。</p>
<h5 id="领导者不在新集群中"><a href="#领导者不在新集群中" class="headerlink" title="领导者不在新集群中"></a>领导者不在新集群中</h5><p>&emsp;&emsp;还有一种可能是<code>领导者</code>不在新集群中，当配置文件从<code>C-old,new</code>变更到<code>C-new</code>时，领导者不在<code>C-new</code>中，这个时候就会在一段时间内发生旧节点管理新集群的情况。<br>&emsp;&emsp;<code>Raft</code>中解决方法很简单，当提交<code>C-new</code>成功的时候，自己的状态变为<code>跟随者</code>，这样<code>领导者</code>节点就只能在新集群中选出。</p>
<h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>&emsp;&emsp;<code>Raft</code>算法在运行的过程中，日志是不断累积的，但是在实际的系统中，无论是从日志占用的磁盘空间，还是新节点加入集群，同步日志的网络消耗来看，日志都不能无限的增长。<br>&emsp;&emsp;<code>Raft</code>采用快照的方法来压缩日志，快照时间点前的日志全部丢弃。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft2/3.png?raw=true" width="70%" height="70%"></p>
<p>&emsp;&emsp;每个服务器根据已经提交的日志，独立创建快照，快照中包含；</p>
<ul>
<li>状态机最后应用的日志；</li>
<li>状态机最后应用日志的任期号；</li>
<li>状态机最后应用的配置文件内容；</li>
</ul>
<p>&emsp;&emsp;<code>领导者</code>周期性的发送一些快照给<code>跟随者</code>，与<code>领导者</code>，保持同步的节点已经提交了快照的内容，会直接丢弃，而运行缓慢或者新加入集群的服务器则不会有这个条目，就会接受并且应用的自己的状态机中。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在前两篇文章中已经介绍了&lt;code&gt;Raft&lt;/code&gt;算法的正常流程和对异常的处理，但是还有一些问题没有解决，比如当集群中有新的节点加入或者退出的时候，集群又该如何保证安全的提供服务呢？&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性协议之Raft(二)</title>
    <link href="qyuan.top/2019/07/16/raft-1/"/>
    <id>qyuan.top/2019/07/16/raft-1/</id>
    <published>2019-07-16T12:29:09.000Z</published>
    <updated>2019-07-16T12:37:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在<a href="http://qyuan.top/2019/07/14/raft/">「分布式一致性协议之Raft（一）」</a>中，描述了<code>Raft</code>在正常情况下的算法流程，但当节点崩溃的情况下会有一些异常，影响状态机顺序的执行相同的指令。</p>
<a id="more"></a>
<h3 id="领导人选举安全（Election-safety）"><a href="#领导人选举安全（Election-safety）" class="headerlink" title="领导人选举安全（Election safety）"></a>领导人选举安全（Election safety）</h3><p>&emsp;&emsp;选举安全性，即在一个任期内最多一个<code>领导人</code>被选出，如果有多余的领导人被选出，则被称为<code>脑裂（brain split）</code>，如果出现<code>脑裂</code>会导致数据的丢失或者覆盖。<code>Raft</code>通过下面两点保证了不会出现<code>脑裂的情况</code>；</p>
<ul>
<li>一个节点某一任期内最多只能投一票；</li>
<li>只有获得大多数选票才能成为领导人；</li>
</ul>
<p>&emsp;&emsp;通过增加约束避免了<code>脑裂</code>的情况出现，保证了同一时间集群中只有一个<code>领导者</code>。但是当一个节点崩溃了一段时间，他的状态机已经落后其他节点很多，突然他重启恢复被选举为<code>领导者</code>，这个时候，客户端发来的请求再经由他复制给其他节点的状态机执行，就会出现集群状态机状态不一致的问题。<br>&emsp;&emsp;其他算法可能会同步落后的日志给领导者，然后在由领导者复制日志给其他节点，但是<code>Raft</code>认为这样会增加算法的复杂性，直接放弃了这种方法，而是采用<code>拒绝</code>投票给那些日志没有自己新的节点。<br>&emsp;&emsp;通过比较两份日志中，最后一条日志条目的索引值和任期号，来定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更新。如果两份日志最后的条目任期号相同，那么日志比索引大的日志新。</p>
<blockquote>
<p><code>拒绝</code>日志比自己旧节点投票是基于这样一种思考，要当选领导者，就必须获得大多数节点的选票，意味着他必须至少比大多数节点的日志新或者一致，这样拒绝比自己旧日志节点的投票请求，就保证了状态比大多数节点落后的节点是不会当选领导者。</p>
</blockquote>
<p>&emsp;&emsp;如果一个<code>领导者</code>把日志复制到大多数其他节点，在应用到状态机之前崩溃了，新选出的领导者，是不知道被复制到大多数节点的日志是否应用到了状态机。</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft1/1.png?raw=true" width="70%" height="70%"></p>
<p>&emsp;&emsp;<b>(a)</b> 中，S1 是领导者，部分的复制了索引位置 2 的日志条目；<br>&emsp;&emsp;<b>(b) </b>中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处；<br>&emsp;&emsp;<b>(c)</b>中，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交；<br>&emsp;&emsp;<b>(d) </b>中，S1又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。注意：<code>虽然s2复制日志过半，但是S5节点的任期号大，日志新，是可以接收S2选票</code>；反之S1在崩溃前把新接收到的日志复制到大多数机器中，如(e)所示的情况。<br>&emsp;&emsp;<b>(e)</b> 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。</p>
<h3 id="候选者和跟随者安全性"><a href="#候选者和跟随者安全性" class="headerlink" title="候选者和跟随者安全性"></a>候选者和跟随者安全性</h3><p>&emsp;&emsp;<code>候选者</code>，<code>跟随者</code>奔溃以后，领导者就是简单的周期性的发送<code>RPC</code>请求，如果重启发生在节点处理完日志复制，响<code>RPC</code>请求之前，收到一样的<code>RPC</code>请求正常返回即可，没有任何问题。如果崩溃时间太长，重启以后落后其他节点日志太多，将会采取<code>快照</code>的方式进行恢复。</p>
<blockquote>
<p><code>Raft</code>的<code>RPC</code>请求是幂等的。</p>
</blockquote>
<h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><p>&emsp;&emsp;<code>Raft</code>的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。这个时候就又会有一些限制；</p>
<ul>
<li>服务器故障的时间必须比消息交换的时间长，否则每当一个节点要收集到足够多选票的时候就宕机了，新一轮的投票又重复这个过程，导致足够的时间选出领导人。</li>
<li>广播的世界必须小于选举超时时间一个数量级，这样领导者才能发送稳定的心跳阻止跟随者进入候选人状态。</li>
<li>当领导者崩溃后，整个系统在大约等于选举超时时间中不可用，所以平均故障间隔时间要大于选举超时时间几个数量级，系统可用性才比较高。<blockquote>
<p>一般来说，广播时间在10毫秒左右，选举超时时间在300毫秒左右，服务器平均故障时间都大于一个月。</p>
</blockquote>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;在&lt;a href=&quot;http://qyuan.top/2019/07/14/raft/&quot;&gt;「分布式一致性协议之Raft（一）」&lt;/a&gt;中，描述了&lt;code&gt;Raft&lt;/code&gt;在正常情况下的算法流程，但当节点崩溃的情况下会有一些异常，影响状态机顺序的执行相同的指令。&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>分布式一致性协议之Raft(一)</title>
    <link href="qyuan.top/2019/07/14/raft/"/>
    <id>qyuan.top/2019/07/14/raft/</id>
    <published>2019-07-14T12:38:08.000Z</published>
    <updated>2019-07-16T12:34:02.361Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;<code>Raft</code>算法解决的核心问题是在分布式环境下如何保持集群状态的一致性，简而言之就是一组服务，给定一组操作，最后得到一致的结果。</p>
<a id="more"></a>
<p>&emsp;&emsp;<code>Raft</code>算法通过选举<code>领导人（leader）</code>，由领导人复制<code>日志（log）</code>到<code>跟随者（follower）</code>，跟随者执行日志指令来达到最后集群状态的一致，整个算法也分成了两部分，领导人如何选举和跟随者如何安全的执行日志指令。</p>
<h3 id="领导人选举"><a href="#领导人选举" class="headerlink" title="领导人选举"></a>领导人选举</h3><p>&emsp;&emsp;<code>Raft</code>算法中一个节点在任意时刻只能处在<code>领导人（leader）</code>，<code>候选人（candidate）</code>，<code>跟随者（follower）</code>，同时强调强领导来简化整个流程，所以他的日志数据流只能从领导人复制到跟随者，跟随者之间也不能传递日志。</p>
<blockquote>
<p>通常情况下，系统中只有一个领导人并且其他节点全部都是跟随者，跟随者都是被动的，他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求</p>
</blockquote>
<p>&emsp;&emsp;下面是三个状态的状态转换图；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft/1.png?raw=true" width="70%" height="70%"></p>
<p>&emsp;&emsp;节点启动的时候，都是跟随者状态，在一段时间没有收到来自领导者的心跳，就从跟随者转变为候选人，发起选举；如果收到含自己的多数选票则转换到领导者；如果发现其他节点比自己更新，则切换到跟随者状态。为了确定其他节点比自己更新，<code>Raft</code>又引入了<code>任期（term）</code>的概念。</p>
<p>&emsp;&emsp;算法起始，任期是0，当有节点当选<code>领导者</code>时，任期号为<code>1</code>，新领导人选出后，任期在之前的任期号加<code>1</code>。当节点从跟随者转化为候选人的时候，任期号也要增加<code>1</code>。</p>
<blockquote>
<p>任期起到逻辑时钟的作用</p>
</blockquote>
<h5 id="选举流程"><a href="#选举流程" class="headerlink" title="选举流程"></a>选举流程</h5><p>&emsp;&emsp;当一个跟随者节点长时间没有收到领导者心跳包，猜测领导者节点可能挂了，发起新领导者节点选举。</p>
<ul>
<li>增加自己当前的<code>任期</code>，转换状态到<code>候选人</code>；</li>
<li>投自己一票，并且给其他节点发送请求给自己投票的请求；</li>
<li>等待其他节点回复，在等待过程中又可能发生下面的情况<ol>
<li>赢得选举，成为领导者；</li>
<li>被告知其他节点当选领导者，自己退回跟随者状态；</li>
<li>超时时间没有收到足够多的选票，则重复整个选举过程；</li>
</ol>
</li>
</ul>
<p>下面的这个gif就展示了这个过程；</p>
<p><img src="https://github.com/Ice-Storm/ice-storm.github.io/blob/master/images/raft/2.gif?raw=true" width="70%" height="70%"></p>
<h3 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h3><p>&emsp;&emsp;当选出了<code>领导人</code>系统就可以对外提供服务，客户端把请求发送给集群，如果是跟随者收到则转发给领导者，由领导者统一处理，领导人会调度这些请求，顺序告知所有跟随者，保证所有节点的状态一致。<br>&emsp;&emsp;<code>Raft</code>是基于复制状态机实现的，其核心思想就是<code>相同的初始状态 + 相同的输入 = 一致的最终状态</code>，领导者将客户端请求打包到一个个<code>log entry</code>，将这些<code>log entries</code>发送到所有跟随者节点，然后大家按相同顺序应用<code>log entry</code>中的命令，则状态肯定是一致的。</p>
<h5 id="复制流程"><a href="#复制流程" class="headerlink" title="复制流程"></a>复制流程</h5><ul>
<li>领导者接收请求打包到<code>log entry</code>；</li>
<li>领导者并行发送<code>log entry</code>到集群所有节点；</li>
<li>领导者收到大多数跟随者收到<code>log entry</code>的回复；</li>
<li>领导者应用<code>log entry</code>里面的命令到自己的状态机中，也就是执行命令；</li>
<li>领导者回复跟随者，并且让他们也执行<code>log entry</code>中命令，达到和自己一致的状态机；</li>
</ul>
<p>&emsp;&emsp;每个<code>log entry</code>中，除了需要执行的命令之外还有领导者节点的任期号，用于处理异常情况；同时我们也可以看到，当日志被复制到大多数节点，即可向客户端返回成功的消息，一旦返回了结果，就必须保证系统在任何异常情况都不会发送回滚。<br>&emsp;&emsp;<code>Raft</code>通过第一个阶段的<code>commited</code>和第二个阶段的<code>apply</code>，保证了状态机的一致性。</p>
<p>&emsp;&emsp;当然还有各种异常情况，我们下篇再讲，讨论细节(<em>╹▽╹</em>)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;&amp;emsp;&lt;code&gt;Raft&lt;/code&gt;算法解决的核心问题是在分布式环境下如何保持集群状态的一致性，简而言之就是一组服务，给定一组操作，最后得到一致的结果。&lt;/p&gt;
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="分布式" scheme="qyuan.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>深入浅出数字证书</title>
    <link href="qyuan.top/2019/07/01/ca/"/>
    <id>qyuan.top/2019/07/01/ca/</id>
    <published>2019-07-01T11:36:53.000Z</published>
    <updated>2019-07-01T11:50:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;&emsp;在<a href="http://qyuan.top/2019/06/23/tls/">「详解TLS/SSL运行机制」</a>这篇文章中，在<code>TLS</code>握手的第三步中，用到了数字证书中的公钥，通过这篇文章，我们一起来看一下为什么会出现数字证书，以及它解决了什么问题。</p>
<a id="more"></a>
<h3 id="无数字证书场景"><a href="#无数字证书场景" class="headerlink" title="无数字证书场景"></a>无数字证书场景</h3><p>&emsp;&emsp;我们假设这样一种不使用证书进行<code>TLS</code>建立连接的场景；</p>
<p>&emsp;&emsp; 在<code>TLS/SSL</code>握手的第一步中，客户端（Client）发送明文消息<code>client_hello</code>给服务端（Server）。<br>&emsp;&emsp; 黑客在服务端收到<code>client_hello</code>之前，截获了这个消息，发送给客户端<code>伪造</code>的协商信息（server_hello）。<br>&emsp;&emsp; 客户端收到黑客发来的伪造的协商信息，如果不验证证书，继续进行后续的秘钥协商过程，流程也是可以走完。</p>
<p>&emsp;&emsp;后续的通信依然使用客户端和服务端协商的秘钥加密通信，但是问题显而易见，我们并没有和最初预想的服务端建立连接，而是和黑客的服务器建立连接。</p>
<blockquote>
<p>黑客可以冒充客户端再和真正的服务端建立连接，黑客作为中间人，监听转发通信。</p>
</blockquote>
<p>&emsp;&emsp;产生这个问题的根源在于，大家都可以生成公私钥对，而我们无法确认这对公私钥到底是属于谁，这个时候就需要一种方法可以证明一对公私钥的所有者是谁。</p>
<h3 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h3><p>&emsp;&emsp;数字证书是一个经<code>数字证书认证机构CA</code>（Certificate Authority）认证签名的文件，包含拥有者的公钥以及相关的身份信息。<br>&emsp;&emsp;用户想要获得证书，应该先向<code>CA</code>提出申请，<code>CA</code>验证申请者的身份后，为其分配一个公钥与其身份信息绑定，为该信息信息进行签名，作为证书的一部分，然后把整个证书发送给申请者。<br>&emsp;&emsp;当需要鉴别证书真伪时，只需要用<code>CA</code>的公钥对证书上的签名进行验证，验证通过则证书有效。</p>
<h3 id="证书结构"><a href="#证书结构" class="headerlink" title="证书结构"></a>证书结构</h3><p>&emsp;&emsp;证书的结构一般遵循<code>X.509</code>规范。<br><img src="https://raw.githubusercontent.com/Ice-Storm/ice-storm.github.io/master/images/ca/1.png" alt="Alt text"></p>
<p>字段含义</p>
<ul>
<li>版本： 使用<code>X.509</code>的版本，目前普遍使用<code>v3</code>版本；</li>
<li>序列号：<code>CA</code>分配给证书的一个整数，作为证书的唯一标识；</li>
<li>签名算法：<code>CA</code>颁发证书使用的签名算法；</li>
<li>有效期：包含证书的起止日期；</li>
<li>主体名：该证书拥有者的名称，如果与颁发者相同则说明证书是一个自签名证书；</li>
<li>公钥信息： 对外公开的公钥以及公钥算法；</li>
<li>扩展信息：通常包含证书的用法，<code>证书吊销列表（Certificate Revocation List，CRL）</code>的发布地址等可选字段；</li>
<li>签名：颁发者用私钥对证书信息的签名；</li>
</ul>
<p>可以通过查看浏览器查看网站证书来快速理解：<br><img src="https://raw.githubusercontent.com/Ice-Storm/ice-storm.github.io/master/images/ca/2.png" alt="Alt text"></p>
<h3 id="证书类型"><a href="#证书类型" class="headerlink" title="证书类型"></a>证书类型</h3><ul>
<li>自签名证书：自签名证书又称根证书，是自己发给自己的证书，证书的颁发者和主体同名；</li>
<li>本地证书：<code>CA</code>颁发给申请者的证书；</li>
<li>设备本地：设备根据CA证书给自己颁发的证书，证书中的颁发者名称是CA服务器的名称。</li>
</ul>
<h3 id="证书格式"><a href="#证书格式" class="headerlink" title="证书格式"></a>证书格式</h3><ul>
<li><code>PKCS#12</code>：<code>#12</code>是标准号，常见后缀是<code>.P12</code>，可包含私钥也可不包含私钥；</li>
<li><code>DER</code>：二进制格式保存证书，不包含私钥，常见后缀<code>.DER</code>;</li>
<li><code>PEM</code>：以ASCII格式保存的证书，可包含私钥，也可不包含私钥，常见后缀<code>.PEM</code>；</li>
</ul>
]]></content>
    
    <summary type="html">
    
      数字证书
    
    </summary>
    
      <category term="区块链" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="密码学" scheme="qyuan.top/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
    
      <category term="区块链" scheme="qyuan.top/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"/>
    
      <category term="密码学" scheme="qyuan.top/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"/>
    
  </entry>
  
</feed>
